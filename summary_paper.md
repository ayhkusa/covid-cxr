# Section II. Summary Paper

## Evolution of Machine Learning

Recent advances in AI and ML have propelled the need to explain the models predictions. As more industries adopting AI/ML for all kinds of applications like forecasting sales, ranking products, rating employees, etc. We need better understanding how these complex AI/ML models behave when it achieves positive predictions as well as failed predictions.

## Who Needs to Know

Data Scientists – These individuals who works and creates ML models. They are the first hands to experience and to reveal the underlining behaviors of the models. Having an explainable model would add value during ML development and troubleshooting. Especially valuable with image type of classifications to aid identify features contributed to predictions.

Domain Experts – These are the individual with specialization in a particular field. Such as doctors that looks at a patient’s x-ray to decide if the case of ailment is positive or negative. Their extensive training and experience would complement the ML models. It is especially critical that when there is a disagreement between the model and human judgement. We need to know how the model made the conclusion and factors it used for the decision.

