{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py converted to notebook\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install dill\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install scikit-imageF\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install imblearn\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.summary as tf_summary\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from math import ceil\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from models.models import *\n",
    "from visualization.visualize import *\n",
    "from custom.metrics import F1Score\n",
    "from data.preprocess import remove_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 10561362632410374242\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 12060270624329687113\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 1691099001822856754\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14648653952\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 18219466431104510833\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(histogram, class_multiplier=None):\n",
    "    '''\n",
    "    Computes weights for each class to be applied in the loss function during training.\n",
    "    :param histogram: A list depicting the number of each item in different class\n",
    "    :param class_multiplier: List of values to multiply the calculated class weights by. For further control of class weighting.\n",
    "    :return: A dictionary containing weights for each class\n",
    "    '''\n",
    "    weights = [None] * len(histogram)\n",
    "    for i in range(len(histogram)):\n",
    "        weights[i] = (1.0 / len(histogram)) * sum(histogram) / histogram[i]\n",
    "    class_weight = {i: weights[i] for i in range(len(histogram))}\n",
    "    if class_multiplier is not None:\n",
    "        class_weight = [class_weight[i] * class_multiplier[i] for i in range(len(histogram))]\n",
    "    print(\"Class weights: \", class_weight)\n",
    "    #debug\n",
    "    print(\"Class weights type:\", type(class_weight))\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minority_oversample(train_set):\n",
    "    '''\n",
    "    Oversample the minority class using the specified algorithm\n",
    "    :param train_set: Training set image file names and labels\n",
    "    :return: A new training set containing oversampled examples\n",
    "    '''\n",
    "    X_train = train_set[[x for x in train_set.columns if x != 'label']].to_numpy()\n",
    "    if X_train.shape[1] == 1:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "    Y_train = train_set['label'].to_numpy()\n",
    "    sampler = RandomOverSampler(random_state=np.random.randint(0, high=1000))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train, Y_train)\n",
    "    filenames = X_resampled[:, 1]     # Filename is in second column\n",
    "    label_strs = X_resampled[:, 2]    # Class name is in second column\n",
    "    print(\"Train set shape before oversampling: \", X_train.shape, \" Train set shape after resampling: \", X_resampled.shape)\n",
    "    train_set_resampled = pd.DataFrame({'filename': filenames, 'label': Y_resampled, 'label_str': label_strs})\n",
    "    return train_set_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg, data, callbacks, verbose=1):\n",
    "    '''\n",
    "    Train a and evaluate model on given data.\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: dict of partitioned dataset\n",
    "    :param callbacks: list of callbacks for Keras model\n",
    "    :param verbose: Verbosity mode to pass to model.fit_generator()\n",
    "    :return: Trained model and associated performance metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # If set in config file, oversample the minority class\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'random_oversample':\n",
    "        data['TRAIN'] = random_minority_oversample(data['TRAIN'])\n",
    "\n",
    "    # Create ImageDataGenerators\n",
    "    train_img_gen = ImageDataGenerator(rotation_range=10, preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    val_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "    # Create DataFrameIterators\n",
    "    img_shape = tuple(cfg['DATA']['IMG_DIM'])\n",
    "    y_col = 'label_str'\n",
    "    class_mode = 'categorical'\n",
    "    train_generator = train_img_gen.flow_from_dataframe(dataframe=data['TRAIN'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    val_generator = val_img_gen.flow_from_dataframe(dataframe=data['VAL'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False, shuffle=False)\n",
    "\n",
    "    # Save model's ordering of class indices\n",
    "    dill.dump(test_generator.class_indices, open(cfg['PATHS']['OUTPUT_CLASS_INDICES'], 'wb'))\n",
    "\n",
    "    # Apply class imbalance strategy. We have many more X-rays negative for COVID-19 than positive.\n",
    "    histogram = np.bincount(np.array(train_generator.labels).astype(int))  # Get class distribution\n",
    "    class_weight = None\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'class_weight':\n",
    "        class_multiplier = cfg['TRAIN']['CLASS_MULTIPLIER']\n",
    "        class_multiplier = [class_multiplier[cfg['DATA']['CLASSES'].index(c)] for c in test_generator.class_indices]\n",
    "        class_weight = get_class_weights(histogram, class_multiplier)\n",
    "\n",
    "    # Define metrics.\n",
    "    covid_class_idx = test_generator.class_indices['COVID-19']   # Get index of COVID-19 class\n",
    "    thresholds = 1.0 / len(cfg['DATA']['CLASSES'])      # Binary classification threshold for a class\n",
    "    metrics = [CategoricalAccuracy(name='accuracy'),\n",
    "               Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               AUC(name='auc'),\n",
    "               F1Score(name='f1score', thresholds=thresholds, class_id=covid_class_idx)]\n",
    "\n",
    "    # Define the model.\n",
    "    print('Training distribution: ', ['Class ' + list(test_generator.class_indices.keys())[i] + ': ' + str(histogram[i]) + '. '\n",
    "           for i in range(len(histogram))])\n",
    "    input_shape = cfg['DATA']['IMG_DIM'] + [3]\n",
    "    num_gpus = cfg['TRAIN']['NUM_GPUS']\n",
    "    #debug\n",
    "    print(\"******* GPU:\", num_gpus)\n",
    "    if cfg['TRAIN']['MODEL_DEF'] == 'dcnn_resnet':\n",
    "        model_def = dcnn_resnet\n",
    "    elif cfg['TRAIN']['MODEL_DEF'] == 'resnet50v2':\n",
    "        model_def = resnet50v2\n",
    "    else:\n",
    "        model_def = resnet101v2\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_BINARY'], input_shape, metrics, 2, output_bias=output_bias, gpus=num_gpus)\n",
    "    else:\n",
    "        n_classes = len(cfg['DATA']['CLASSES'])\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_MULTICLASS'], input_shape, metrics, n_classes, output_bias=output_bias,\n",
    "                          gpus=num_gpus)\n",
    "    #debug\n",
    "    print(\"histogram type\", type(histogram), histogram)\n",
    "        \n",
    "    # Train the model.\n",
    "    steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
    "    val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
    "    # debug\n",
    "    print(\"***** class weight\", class_weight)\n",
    "    class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg['TRAIN']['EPOCHS'],\n",
    "                                  validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
    "                                  verbose=verbose, class_weight=class_weight)\n",
    "\n",
    "    # Run the model on the test set and print the resulting performance metrics.\n",
    "    test_results = model.evaluate(test_generator, verbose=1)\n",
    "    test_metrics = {}\n",
    "    test_summary_str = [['**Metric**', '**Value**']]\n",
    "    for metric, value in zip(model.metrics_names, test_results):\n",
    "        test_metrics[metric] = value\n",
    "        print(metric, ' = ', value)\n",
    "        test_summary_str.append([metric, str(value)])\n",
    "    return model, test_metrics, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "#print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_train(cfg, data, callbacks, base_log_dir):\n",
    "    '''\n",
    "    Trains a model a series of times and returns the model with the best test set metric (specified in cfg)\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: Partitioned dataset\n",
    "    :param callbacks: List of callbacks to pass to model.fit()\n",
    "    :param base_log_dir: Base directory to write logs\n",
    "    :return: The trained Keras model with best test set performance on the metric specified in cfg\n",
    "    '''\n",
    "\n",
    "    # Load order of metric preference\n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    best_metrics = dict.fromkeys(metric_preference, 0.0)\n",
    "    if 'loss' in metric_preference:\n",
    "        best_metrics['loss'] = 100000.0\n",
    "\n",
    "    # Train NUM_RUNS models and return the best one according to the preferred metrics\n",
    "    for i in range(cfg['TRAIN']['NUM_RUNS']):\n",
    "        print(\"Training run \", i+1, \" / \", cfg['TRAIN']['NUM_RUNS'])\n",
    "        cur_callbacks = callbacks.copy()\n",
    "        cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if base_log_dir is not None:\n",
    "            log_dir = base_log_dir + cur_date\n",
    "            cur_callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\n",
    "        # Train the model and evaluate performance on test set\n",
    "        new_model, test_metrics, test_generator = train_model(cfg, data, cur_callbacks, verbose=1)\n",
    "\n",
    "        # Log test set results and images\n",
    "        if base_log_dir is not None:\n",
    "            log_test_results(cfg, new_model, test_generator, test_metrics, log_dir)\n",
    "\n",
    "        # If this model outperforms the previous ones based on the specified metric preferences, save this one.\n",
    "        for i in range(len(metric_preference)):\n",
    "            if (((metric_preference[i] == 'loss') and (test_metrics[metric_preference[i]] < best_metrics[metric_preference[i]]))\n",
    "                    or ((metric_preference[i] != 'loss') and (test_metrics[metric_preference[i]] > best_metrics[metric_preference[i]]))):\n",
    "                best_model = new_model\n",
    "                best_metrics = test_metrics\n",
    "                best_generator = test_generator\n",
    "                best_model_date = cur_date\n",
    "                break\n",
    "            elif (test_metrics[metric_preference[i]] == best_metrics[metric_preference[i]]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(\"Best model test metrics: \", best_metrics)\n",
    "    return best_model, best_metrics, best_generator, best_model_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_hparam_search(cfg, data, callbacks, log_dir):\n",
    "    '''\n",
    "    Conduct a random hyperparameter search over the ranges given for the hyperparameters in config.yml and log results\n",
    "    in TensorBoard. Model is trained x times for y random combinations of hyperparameters.\n",
    "    :param cfg: Project config\n",
    "    :param data: Dict containing the partitioned datasets\n",
    "    :param callbacks: List of callbacks for Keras model (excluding TensorBoard)\n",
    "    :param log_dir: Base directory in which to store logs\n",
    "    :return: (Last model trained, resultant test set metrics, test data generator)\n",
    "    '''\n",
    "\n",
    "    # Define HParam objects for each hyperparameter we wish to tune.\n",
    "    hp_ranges = cfg['HP_SEARCH']['RANGES']\n",
    "    HPARAMS = []\n",
    "    HPARAMS.append(hp.HParam('KERNEL_SIZE', hp.Discrete(hp_ranges['KERNEL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('MAXPOOL_SIZE', hp.Discrete(hp_ranges['MAXPOOL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('INIT_FILTERS', hp.Discrete(hp_ranges['INIT_FILTERS'])))\n",
    "    HPARAMS.append(hp.HParam('FILTER_EXP_BASE', hp.IntInterval(hp_ranges['FILTER_EXP_BASE'][0], hp_ranges['FILTER_EXP_BASE'][1])))\n",
    "    HPARAMS.append(hp.HParam('NODES_DENSE0', hp.Discrete(hp_ranges['NODES_DENSE0'])))\n",
    "    HPARAMS.append(hp.HParam('CONV_BLOCKS', hp.IntInterval(hp_ranges['CONV_BLOCKS'][0], hp_ranges['CONV_BLOCKS'][1])))\n",
    "    HPARAMS.append(hp.HParam('DROPOUT', hp.Discrete(hp_ranges['DROPOUT'])))\n",
    "    HPARAMS.append(hp.HParam('LR', hp.RealInterval(hp_ranges['LR'][0], hp_ranges['LR'][1])))\n",
    "    HPARAMS.append(hp.HParam('OPTIMIZER', hp.Discrete(hp_ranges['OPTIMIZER'])))\n",
    "    HPARAMS.append(hp.HParam('L2_LAMBDA', hp.Discrete(hp_ranges['L2_LAMBDA'])))\n",
    "    HPARAMS.append(hp.HParam('BATCH_SIZE', hp.Discrete(hp_ranges['BATCH_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('IMB_STRATEGY', hp.Discrete(hp_ranges['IMB_STRATEGY'])))\n",
    "\n",
    "    # Define test set metrics that we wish to log to TensorBoard for each training run\n",
    "    HP_METRICS = [hp.Metric(metric, display_name='Test ' + metric) for metric in cfg['HP_SEARCH']['METRICS']]\n",
    "\n",
    "    # Configure TensorBoard to log the results\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=HP_METRICS)\n",
    "\n",
    "    # Complete a number of training runs at different hparam values and log the results.\n",
    "    repeats_per_combo = cfg['HP_SEARCH']['REPEATS']   # Number of times to train the model per combination of hparams\n",
    "    num_combos = cfg['HP_SEARCH']['COMBINATIONS']     # Number of random combinations of hparams to attempt\n",
    "    num_sessions = num_combos * repeats_per_combo       # Total number of runs in this experiment\n",
    "    model_type = 'DCNN_BINARY' if cfg['TRAIN']['CLASS_MODE'] == 'binary' else 'DCNN_MULTICLASS'\n",
    "    trial_id = 0\n",
    "    for group_idx in range(num_combos):\n",
    "        rand = random.Random()\n",
    "        HPARAMS = {h: h.domain.sample_uniform(rand) for h in HPARAMS}\n",
    "        hparams = {h.name: HPARAMS[h] for h in HPARAMS}  # To pass to model definition\n",
    "        for repeat_idx in range(repeats_per_combo):\n",
    "            trial_id += 1\n",
    "            print(\"Running training session %d/%d\" % (trial_id, num_sessions))\n",
    "            print(\"Hparam values: \", {h.name: HPARAMS[h] for h in HPARAMS})\n",
    "            trial_logdir = os.path.join(log_dir, str(trial_id))     # Need specific logdir for each trial\n",
    "            callbacks_hp = callbacks + [TensorBoard(log_dir=trial_logdir, profile_batch=0, write_graph=False)]\n",
    "\n",
    "            # Set values of hyperparameters for this run in config file.\n",
    "            for h in hparams:\n",
    "                if h in ['LR', 'L2_LAMBDA']:\n",
    "                    val = 10 ** hparams[h]      # These hyperparameters are sampled on the log scale.\n",
    "                else:\n",
    "                    val = hparams[h]\n",
    "                cfg['NN'][model_type][h] = val\n",
    "\n",
    "            # Set some hyperparameters that are not specified in model definition.\n",
    "            cfg['TRAIN']['BATCH_SIZE'] = hparams['BATCH_SIZE']\n",
    "            cfg['TRAIN']['IMB_STRATEGY'] = hparams['IMB_STRATEGY']\n",
    "\n",
    "            # Run a training session and log the performance metrics on the test set to HParams dashboard in TensorBoard\n",
    "            with tf.summary.create_file_writer(trial_logdir).as_default():\n",
    "                hp.hparams(HPARAMS, trial_id=str(trial_id))\n",
    "                model, test_metrics, test_generator = train_model(cfg, data, callbacks_hp, verbose=0)\n",
    "                for metric in HP_METRICS:\n",
    "                    if metric._tag in test_metrics:\n",
    "                        tf.summary.scalar(metric._tag, test_metrics[metric._tag], step=1)   # Log test metric\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_results(cfg, model, test_generator, test_metrics, log_dir):\n",
    "    '''\n",
    "    Visualize performance of a trained model on the test set. Optionally save the model.\n",
    "    :param cfg: Project config\n",
    "    :param model: A trained Keras model\n",
    "    :param test_generator: A Keras generator for the test set\n",
    "    :param test_metrics: Dict of test set performance metrics\n",
    "    :param log_dir: Path to write TensorBoard logs\n",
    "    '''\n",
    "\n",
    "    # Visualization of test results\n",
    "    test_predictions = model.predict(test_generator, verbose=0)\n",
    "    test_labels = test_generator.labels\n",
    "    covid_idx = test_generator.class_indices['COVID-19']\n",
    "    plt = plot_roc(\"Test set\", test_labels, test_predictions, class_id=covid_idx)\n",
    "    roc_img = plot_to_tensor()\n",
    "    plt = plot_confusion_matrix(test_labels, test_predictions, class_id=covid_idx)\n",
    "    cm_img = plot_to_tensor()\n",
    "\n",
    "    # Log test set results and plots in TensorBoard\n",
    "    writer = tf_summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "    # Create table of test set metrics\n",
    "    test_summary_str = [['**Metric**','**Value**']]\n",
    "    thresholds = cfg['TRAIN']['THRESHOLDS']  # Load classification thresholds\n",
    "    for metric in test_metrics:\n",
    "        if metric in ['precision', 'recall'] and isinstance(metric, list):\n",
    "            metric_values = dict(zip(thresholds, test_metrics[metric]))\n",
    "        else:\n",
    "            metric_values = test_metrics[metric]\n",
    "        test_summary_str.append([metric, str(metric_values)])\n",
    "\n",
    "    # Create table of model and train config values\n",
    "    hparam_summary_str = [['**Variable**', '**Value**']]\n",
    "    for key in cfg['TRAIN']:\n",
    "        hparam_summary_str.append([key, str(cfg['TRAIN'][key])])\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "    else:\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "\n",
    "    # Write to TensorBoard logs\n",
    "    with writer.as_default():\n",
    "        tf_summary.text(name='Test set metrics', data=tf.convert_to_tensor(test_summary_str), step=0)\n",
    "        tf_summary.text(name='Run hyperparameters', data=tf.convert_to_tensor(hparam_summary_str), step=0)\n",
    "        tf_summary.image(name='ROC Curve (Test Set)', data=roc_img, step=0)\n",
    "        tf_summary.image(name='Confusion Matrix (Test Set)', data=cm_img, step=0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment(cfg=None, experiment='single_train', save_weights=True, write_logs=True):\n",
    "    '''\n",
    "    Defines and trains HIFIS-v2 model. Prints and logs relevant metrics.\n",
    "    :param experiment: The type of training experiment. Choices are {'single_train'}\n",
    "    :param save_weights: A flag indicating whether to save the model weights\n",
    "    :param write_logs: A flag indicating whether to write TensorBoard logs\n",
    "    :return: A dictionary of metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    if cfg is None:\n",
    "        cfg = yaml.full_load(open(os.getcwd() + \"/config.yml\", 'r'))\n",
    "\n",
    "    # Set logs directory\n",
    "    cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    print(cfg['PATHS']['LOGS'])\n",
    "    log_dir = cfg['PATHS']['LOGS'] + \"training/\" + cur_date if write_logs else None\n",
    "    if not os.path.exists(cfg['PATHS']['LOGS'] + \"training\\\\\"):\n",
    "        os.makedirs(cfg['PATHS']['LOGS'] + \"training\\\\\")\n",
    "\n",
    "    # Load dataset file paths and labels\n",
    "    data = {}\n",
    "    data['TRAIN'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    data['VAL'] = pd.read_csv(cfg['PATHS']['VAL_SET'])\n",
    "    data['TEST'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Set callbacks.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=cfg['TRAIN']['PATIENCE'], mode='min', restore_best_weights=True)\n",
    "    callbacks = [early_stopping]\n",
    "\n",
    "    # Conduct the desired train experiment\n",
    "    if experiment == 'hparam_search':\n",
    "        log_dir = cfg['PATHS']['LOGS'] + \"hparam_search\\\\\" + cur_date\n",
    "        random_hparam_search(cfg, data, callbacks, log_dir)\n",
    "    else:\n",
    "        if experiment == 'multi_train':\n",
    "            base_log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" if write_logs else None\n",
    "            model, test_metrics, test_generator, cur_date = multi_train(cfg, data, callbacks, base_log_dir)\n",
    "        else:\n",
    "            if write_logs:\n",
    "                tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                callbacks.append(tensorboard)\n",
    "            #\n",
    "            print(cfg)\n",
    "            print(data)\n",
    "            print(callbacks)\n",
    "            model, test_metrics, test_generator = train_model(cfg, data, callbacks)\n",
    "            if write_logs:\n",
    "                log_test_results(cfg, model, test_generator, test_metrics, log_dir)\n",
    "        if save_weights:\n",
    "            model_path = cfg['PATHS']['MODEL_WEIGHTS'] + 'model' + cur_date + '.h5'\n",
    "            save_model(model, model_path)  # Save the model's weights\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/covid-cxr/results/logs/\n",
      "{'PATHS': {'RAW_DATA': '/home/ubuntu/covid-cxr/data/', 'MILA_DATA': '/home/ubuntu/covid-cxr/data/covid-chestxray-dataset/', 'FIGURE1_DATA': '/home/ubuntu/covid-cxr/data/Figure1-COVID-chestxray-dataset/', 'RSNA_DATA': '/home/ubuntu/covid-cxr/data/rsna/', 'PROCESSED_DATA': 'data/processed/', 'TRAIN_SET': '/home/ubuntu/covid-cxr/data/processed/train_set.csv', 'VAL_SET': '/home/ubuntu/covid-cxr/data/processed/val_set.csv', 'TEST_SET': '/home/ubuntu/covid-cxr/data/processed/test_set.csv', 'IMAGES': '/home/ubuntu/covid-cxr/documents/generated_images/', 'LOGS': '/home/ubuntu/covid-cxr/results/logs/', 'MODEL_WEIGHTS': '/home/ubuntu/covid-cxr/results/models/', 'MODEL_TO_LOAD': '/home/ubuntu/covid-cxr/results/models/model.h5', 'LIME_EXPLAINER': '/home/ubuntu/covid-cxr/data/interpretability/lime_explainer.pkl', 'OUTPUT_CLASS_INDICES': '/home/ubuntu/covid-cxr/data/interpretability/output_class_indices.pkl', 'BATCH_PRED_IMGS': '/home/ubuntu/covid-cxr/data/processed/test/', 'BATCH_PREDS': '/home/ubuntu/covid-cxr/results/predictions/'}, 'DATA': {'IMG_DIM': [224, 224], 'VIEWS': ['PA', 'AP'], 'VAL_SPLIT': 0.08, 'TEST_SPLIT': 0.1, 'NUM_RSNA_IMGS': 1000, 'CLASSES': ['non-COVID-19', 'COVID-19']}, 'TRAIN': {'CLASS_MODE': 'binary', 'MODEL_DEF': 'dcnn_resnet', 'CLASS_MULTIPLIER': [0.15, 1.0], 'EXPERIMENT_TYPE': 'single_train', 'BATCH_SIZE': 32, 'EPOCHS': 50, 'THRESHOLDS': 0.5, 'PATIENCE': 7, 'IMB_STRATEGY': 'class_weight', 'METRIC_PREFERENCE': ['auc', 'recall', 'precision', 'loss'], 'NUM_RUNS': 10, 'NUM_GPUS': 1}, 'NN': {'DCNN_BINARY': {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}, 'DCNN_MULTICLASS': {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 4, 'NODES_DENSE0': 128, 'LR': 0.0002, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}}, 'LIME': {'KERNEL_WIDTH': 1.75, 'FEATURE_SELECTION': 'lasso_path', 'NUM_FEATURES': 1000, 'NUM_SAMPLES': 1000, 'COVID_ONLY': False}, 'HP_SEARCH': {'METRICS': ['accuracy', 'loss', 'recall', 'precision', 'auc'], 'COMBINATIONS': 50, 'REPEATS': 2, 'RANGES': {'KERNEL_SIZE': ['(3,3)', '(5,5)'], 'MAXPOOL_SIZE': ['(2,2)', '(3,3)'], 'INIT_FILTERS': [8, 16, 32], 'FILTER_EXP_BASE': [2, 3], 'NODES_DENSE0': [128, 256, 512, 1024], 'CONV_BLOCKS': [3, 8], 'DROPOUT': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], 'LR': [-5.0, -3.0], 'OPTIMIZER': ['adam'], 'L2_LAMBDA': [0.0, 1e-05, 0.0001, 0.001], 'BATCH_SIZE': [16, 32], 'IMB_STRATEGY': ['class_weight']}}, 'PREDICTION': {'THRESHOLD': 0.5}}\n",
      "{'TRAIN':       Unnamed: 0                                           filename  label  \\\n",
      "0            601  covid-chestxray-dataset/images/1-s2.0-S1341321...      0   \n",
      "1             97      rsna/02285fa4-35b7-4af6-b88f-3cac45a7f5c8.jpg      0   \n",
      "2            783       covid-chestxray-dataset/images/16497_1_1.png      0   \n",
      "3            189  covid-chestxray-dataset/images/covid-19-infect...      0   \n",
      "4            665      rsna/09629e2b-7f1e-499c-aab7-2bff196f034b.jpg      0   \n",
      "...          ...                                                ...    ...   \n",
      "1484         699      rsna/098e14d4-3205-4c2d-a059-738f830c0aa5.jpg      0   \n",
      "1485         359  covid-chestxray-dataset/images/covid-19-pneumo...      0   \n",
      "1486         347    covid-chestxray-dataset/images/extubation-8.jpg      0   \n",
      "1487         860        covid-chestxray-dataset/images/1e33b16c.jpg      0   \n",
      "1488         109      rsna/02de2d68-b7f9-428b-ac12-0cb8f56a0145.jpg      0   \n",
      "\n",
      "         label_str  \n",
      "0     non-COVID-19  \n",
      "1     non-COVID-19  \n",
      "2     non-COVID-19  \n",
      "3     non-COVID-19  \n",
      "4     non-COVID-19  \n",
      "...            ...  \n",
      "1484  non-COVID-19  \n",
      "1485  non-COVID-19  \n",
      "1486  non-COVID-19  \n",
      "1487  non-COVID-19  \n",
      "1488  non-COVID-19  \n",
      "\n",
      "[1489 rows x 4 columns], 'VAL':      Unnamed: 0                                           filename  label  \\\n",
      "0           437        covid-chestxray-dataset/images/bb0e626a.jpg      0   \n",
      "1            39      rsna/01a4059c-22f7-4f51-8a27-50aff0b3aeb3.jpg      0   \n",
      "2            72  covid-chestxray-dataset/images/7C69C012-7479-4...      0   \n",
      "3           133      rsna/03d92597-3e33-4fdf-8db5-a27cf5b8d3eb.jpg      0   \n",
      "4            37  Figure1-COVID-chestxray-dataset/images/COVID-0...      1   \n",
      "..          ...                                                ...    ...   \n",
      "141         913  covid-chestxray-dataset/images/3e9d9c9b02b9bcd...      0   \n",
      "142         508      rsna/082fd63e-aec4-401a-822b-eb10d98b562c.jpg      0   \n",
      "143         842        covid-chestxray-dataset/images/0cea09eb.jpg      0   \n",
      "144         202  covid-chestxray-dataset/images/pneumocystis-ji...      0   \n",
      "145         365      rsna/07166637-dcb4-40c0-b553-257690afa9be.jpg      0   \n",
      "\n",
      "        label_str  \n",
      "0    non-COVID-19  \n",
      "1    non-COVID-19  \n",
      "2    non-COVID-19  \n",
      "3    non-COVID-19  \n",
      "4        COVID-19  \n",
      "..            ...  \n",
      "141  non-COVID-19  \n",
      "142  non-COVID-19  \n",
      "143  non-COVID-19  \n",
      "144  non-COVID-19  \n",
      "145  non-COVID-19  \n",
      "\n",
      "[146 rows x 4 columns], 'TEST':      Unnamed: 0                                           filename  label  \\\n",
      "0           884        covid-chestxray-dataset/images/c873402e.jpg      0   \n",
      "1           442      rsna/07a16de4-9d4c-4e88-a980-37734b8a4cdd.jpg      0   \n",
      "2           967      rsna/0bbe0f92-940f-431a-b8c4-3b371ea7d9aa.jpg      0   \n",
      "3           422      rsna/07752357-2f21-4e42-9015-27886b3d5857.jpg      0   \n",
      "4           996      rsna/0bf44996-58da-4a12-8be1-da5c9b009975.jpg      0   \n",
      "..          ...                                                ...    ...   \n",
      "177         131      rsna/03cd7a5b-d5d7-40a1-81b1-c4264920530a.jpg      0   \n",
      "178         556  covid-chestxray-dataset/images/11547_2020_1200...      0   \n",
      "179         147  covid-chestxray-dataset/images/03BF7561-A9BA-4...      0   \n",
      "180         731      rsna/09d41130-fc56-4a25-96f0-862f00a790cb.jpg      0   \n",
      "181         357     covid-chestxray-dataset/images/case_76_1-3.png      0   \n",
      "\n",
      "        label_str  \n",
      "0    non-COVID-19  \n",
      "1    non-COVID-19  \n",
      "2    non-COVID-19  \n",
      "3    non-COVID-19  \n",
      "4    non-COVID-19  \n",
      "..            ...  \n",
      "177  non-COVID-19  \n",
      "178  non-COVID-19  \n",
      "179  non-COVID-19  \n",
      "180  non-COVID-19  \n",
      "181  non-COVID-19  \n",
      "\n",
      "[182 rows x 4 columns]}\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f69aa5bcd10>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f69b52c2d10>]\n",
      "Found 1489 non-validated image filenames belonging to 2 classes.\n",
      "Found 146 non-validated image filenames belonging to 2 classes.\n",
      "Found 182 non-validated image filenames belonging to 2 classes.\n",
      "Class weights:  [26.589285714285715, 0.07643737166324435]\n",
      "Class weights type: <class 'list'>\n",
      "Training distribution:  ['Class COVID-19: 28. ', 'Class non-COVID-19: 1461. ']\n",
      "******* GPU: 1\n",
      "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0_0 (Conv2D)                (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv0_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 224, 224, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, 224, 224, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat0 (Concatenate)           (None, 224, 224, 19) 0           conv0_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 19) 76          concat0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 19) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 19) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_0 (Conv2D)                (None, 112, 112, 48) 8256        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 48) 192         conv1_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 112, 112, 48) 20784       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 112, 112, 67) 0           conv1_1[0][0]                    \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 67) 268         concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 112, 112, 67) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 67)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_0 (Conv2D)                (None, 56, 56, 144)  86976       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 144)  576         conv2_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 144)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 56, 56, 144)  186768      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 56, 56, 211)  0           conv2_1[0][0]                    \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 211)  844         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 211)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 211)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 165424)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 165424)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21174400    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,482,230\n",
      "Trainable params: 21,481,220\n",
      "Non-trainable params: 1,010\n",
      "__________________________________________________________________________________________________\n",
      "histogram type <class 'numpy.ndarray'> [1461   28]\n",
      "***** class weight [26.589285714285715, 0.07643737166324435]\n",
      "Epoch 1/50\n",
      " 1/47 [..............................] - ETA: 0s - loss: 515.3688 - accuracy: 0.0312 - precision: 0.0312 - recall: 1.0000 - auc: 0.0322 - f1score: 0.0606WARNING:tensorflow:From /opt/tljh/user/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "47/47 [==============================] - 69s 1s/step - loss: 494.9458 - accuracy: 0.3445 - precision: 0.0212 - recall: 0.7500 - auc: 0.3130 - f1score: 0.0413 - val_loss: 447.9515 - val_accuracy: 0.0205 - val_precision: 0.0205 - val_recall: 1.0000 - val_auc: 0.0205 - val_f1score: 0.0403\n",
      "Epoch 2/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 464.7123 - accuracy: 0.1800 - precision: 0.0209 - recall: 0.9286 - auc: 0.1229 - f1score: 0.0408 - val_loss: 377.8237 - val_accuracy: 0.0205 - val_precision: 0.0205 - val_recall: 1.0000 - val_auc: 0.0235 - val_f1score: 0.0403\n",
      "Epoch 3/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 441.2484 - accuracy: 0.3620 - precision: 0.0267 - recall: 0.9286 - auc: 0.3340 - f1score: 0.0519 - val_loss: 356.9416 - val_accuracy: 0.0890 - val_precision: 0.0221 - val_recall: 1.0000 - val_auc: 0.0512 - val_f1score: 0.0432\n",
      "Epoch 4/50\n",
      "47/47 [==============================] - 68s 1s/step - loss: 421.5147 - accuracy: 0.3566 - precision: 0.0255 - recall: 0.8929 - auc: 0.3312 - f1score: 0.0496 - val_loss: 350.6098 - val_accuracy: 0.2671 - val_precision: 0.0273 - val_recall: 1.0000 - val_auc: 0.2111 - val_f1score: 0.0531\n",
      "Epoch 5/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 404.4701 - accuracy: 0.3103 - precision: 0.0247 - recall: 0.9286 - auc: 0.2880 - f1score: 0.0482 - val_loss: 351.7026 - val_accuracy: 0.1781 - val_precision: 0.0244 - val_recall: 1.0000 - val_auc: 0.1461 - val_f1score: 0.0476\n",
      "Epoch 6/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 389.5422 - accuracy: 0.3445 - precision: 0.0260 - recall: 0.9286 - auc: 0.3076 - f1score: 0.0506 - val_loss: 356.7269 - val_accuracy: 0.0753 - val_precision: 0.0217 - val_recall: 1.0000 - val_auc: 0.0536 - val_f1score: 0.0426\n",
      "Epoch 7/50\n",
      "47/47 [==============================] - 68s 1s/step - loss: 376.1639 - accuracy: 0.3909 - precision: 0.0279 - recall: 0.9286 - auc: 0.3559 - f1score: 0.0542 - val_loss: 352.7029 - val_accuracy: 0.6507 - val_precision: 0.0385 - val_recall: 0.6667 - val_auc: 0.7184 - val_f1score: 0.0727\n",
      "Epoch 8/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 364.0983 - accuracy: 0.4694 - precision: 0.0308 - recall: 0.8929 - auc: 0.4476 - f1score: 0.0595 - val_loss: 355.3603 - val_accuracy: 0.2877 - val_precision: 0.0280 - val_recall: 1.0000 - val_auc: 0.2575 - val_f1score: 0.0545\n",
      "Epoch 9/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 352.7150 - accuracy: 0.5265 - precision: 0.0369 - recall: 0.9643 - auc: 0.5475 - f1score: 0.0711 - val_loss: 352.4090 - val_accuracy: 0.4178 - val_precision: 0.0341 - val_recall: 1.0000 - val_auc: 0.4321 - val_f1score: 0.0659\n",
      "Epoch 10/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 342.7954 - accuracy: 0.5695 - precision: 0.0391 - recall: 0.9286 - auc: 0.6248 - f1score: 0.0750 - val_loss: 348.4818 - val_accuracy: 0.4589 - val_precision: 0.0366 - val_recall: 1.0000 - val_auc: 0.4792 - val_f1score: 0.0706\n",
      "Epoch 11/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 333.4868 - accuracy: 0.6313 - precision: 0.0454 - recall: 0.9286 - auc: 0.6795 - f1score: 0.0865 - val_loss: 343.9974 - val_accuracy: 0.3973 - val_precision: 0.0330 - val_recall: 1.0000 - val_auc: 0.4047 - val_f1score: 0.0638\n",
      "Epoch 12/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 325.2947 - accuracy: 0.4748 - precision: 0.0334 - recall: 0.9643 - auc: 0.4704 - f1score: 0.0646 - val_loss: 336.6499 - val_accuracy: 0.6027 - val_precision: 0.0492 - val_recall: 1.0000 - val_auc: 0.6815 - val_f1score: 0.0938\n",
      "Epoch 13/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 317.6324 - accuracy: 0.5541 - precision: 0.0378 - recall: 0.9286 - auc: 0.5709 - f1score: 0.0726 - val_loss: 340.8318 - val_accuracy: 0.1233 - val_precision: 0.0229 - val_recall: 1.0000 - val_auc: 0.0849 - val_f1score: 0.0448\n",
      "Epoch 14/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 310.3485 - accuracy: 0.5709 - precision: 0.0406 - recall: 0.9643 - auc: 0.6048 - f1score: 0.0779 - val_loss: 324.3214 - val_accuracy: 0.6438 - val_precision: 0.0377 - val_recall: 0.6667 - val_auc: 0.7281 - val_f1score: 0.0714\n",
      "Epoch 15/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 303.4527 - accuracy: 0.7710 - precision: 0.0759 - recall: 1.0000 - auc: 0.8426 - f1score: 0.1411 - val_loss: 317.7766 - val_accuracy: 0.7397 - val_precision: 0.0513 - val_recall: 0.6667 - val_auc: 0.8142 - val_f1score: 0.0952\n",
      "Epoch 16/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 297.4464 - accuracy: 0.5621 - precision: 0.0398 - recall: 0.9643 - auc: 0.5732 - f1score: 0.0765 - val_loss: 312.1656 - val_accuracy: 0.7260 - val_precision: 0.0488 - val_recall: 0.6667 - val_auc: 0.7967 - val_f1score: 0.0909\n",
      "Epoch 17/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 291.6129 - accuracy: 0.5910 - precision: 0.0396 - recall: 0.8929 - auc: 0.6088 - f1score: 0.0759 - val_loss: 320.3354 - val_accuracy: 0.0822 - val_precision: 0.0219 - val_recall: 1.0000 - val_auc: 0.0490 - val_f1score: 0.0429\n",
      "Epoch 18/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 286.0219 - accuracy: 0.5077 - precision: 0.0356 - recall: 0.9643 - auc: 0.5138 - f1score: 0.0686 - val_loss: 306.2219 - val_accuracy: 0.2671 - val_precision: 0.0273 - val_recall: 1.0000 - val_auc: 0.2382 - val_f1score: 0.0531\n",
      "Epoch 19/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 280.3448 - accuracy: 0.7340 - precision: 0.0640 - recall: 0.9643 - auc: 0.7978 - f1score: 0.1200 - val_loss: 296.4887 - val_accuracy: 0.6370 - val_precision: 0.0370 - val_recall: 0.6667 - val_auc: 0.7539 - val_f1score: 0.0702\n",
      "Epoch 20/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 275.4818 - accuracy: 0.5816 - precision: 0.0402 - recall: 0.9286 - auc: 0.6100 - f1score: 0.0770 - val_loss: 299.8391 - val_accuracy: 0.1644 - val_precision: 0.0240 - val_recall: 1.0000 - val_auc: 0.1421 - val_f1score: 0.0469\n",
      "Epoch 21/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 270.9519 - accuracy: 0.4271 - precision: 0.0296 - recall: 0.9286 - auc: 0.4247 - f1score: 0.0575 - val_loss: 291.4159 - val_accuracy: 0.2808 - val_precision: 0.0278 - val_recall: 1.0000 - val_auc: 0.2369 - val_f1score: 0.0541\n",
      "Epoch 22/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 265.9879 - accuracy: 0.7851 - precision: 0.0805 - recall: 1.0000 - auc: 0.8487 - f1score: 0.1489 - val_loss: 282.8383 - val_accuracy: 0.6712 - val_precision: 0.0408 - val_recall: 0.6667 - val_auc: 0.7291 - val_f1score: 0.0769\n",
      "Epoch 23/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 261.6032 - accuracy: 0.8509 - precision: 0.1089 - recall: 0.9643 - auc: 0.9235 - f1score: 0.1957 - val_loss: 278.8210 - val_accuracy: 0.6438 - val_precision: 0.0377 - val_recall: 0.6667 - val_auc: 0.6827 - val_f1score: 0.0714\n",
      "Epoch 24/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 257.3660 - accuracy: 0.6682 - precision: 0.0536 - recall: 1.0000 - auc: 0.7115 - f1score: 0.1018 - val_loss: 274.5491 - val_accuracy: 0.6712 - val_precision: 0.0408 - val_recall: 0.6667 - val_auc: 0.7384 - val_f1score: 0.0769\n",
      "Epoch 25/50\n",
      "47/47 [==============================] - 68s 1s/step - loss: 253.3792 - accuracy: 0.6481 - precision: 0.0491 - recall: 0.9643 - auc: 0.6883 - f1score: 0.0934 - val_loss: 270.3957 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7891 - val_f1score: 0.0870\n",
      "Epoch 26/50\n",
      "47/47 [==============================] - 68s 1s/step - loss: 249.4563 - accuracy: 0.6521 - precision: 0.0496 - recall: 0.9643 - auc: 0.6792 - f1score: 0.0944 - val_loss: 266.5369 - val_accuracy: 0.6644 - val_precision: 0.0400 - val_recall: 0.6667 - val_auc: 0.7570 - val_f1score: 0.0755\n",
      "Epoch 27/50\n",
      "47/47 [==============================] - 68s 1s/step - loss: 245.5743 - accuracy: 0.7441 - precision: 0.0663 - recall: 0.9643 - auc: 0.8104 - f1score: 0.1241 - val_loss: 263.1646 - val_accuracy: 0.6575 - val_precision: 0.0392 - val_recall: 0.6667 - val_auc: 0.7594 - val_f1score: 0.0741\n",
      "Epoch 28/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 242.0783 - accuracy: 0.7347 - precision: 0.0641 - recall: 0.9643 - auc: 0.7951 - f1score: 0.1203 - val_loss: 259.7154 - val_accuracy: 0.6712 - val_precision: 0.0408 - val_recall: 0.6667 - val_auc: 0.7551 - val_f1score: 0.0769\n",
      "Epoch 29/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 238.5446 - accuracy: 0.7159 - precision: 0.0582 - recall: 0.9286 - auc: 0.7745 - f1score: 0.1095 - val_loss: 255.1298 - val_accuracy: 0.8973 - val_precision: 0.1250 - val_recall: 0.6667 - val_auc: 0.9460 - val_f1score: 0.2105\n",
      "Epoch 30/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 235.0224 - accuracy: 0.7931 - precision: 0.0833 - recall: 1.0000 - auc: 0.8690 - f1score: 0.1538 - val_loss: 252.4617 - val_accuracy: 0.7603 - val_precision: 0.0556 - val_recall: 0.6667 - val_auc: 0.8614 - val_f1score: 0.1026\n",
      "Epoch 31/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 231.8894 - accuracy: 0.7246 - precision: 0.0619 - recall: 0.9643 - auc: 0.7684 - f1score: 0.1164 - val_loss: 262.4481 - val_accuracy: 0.1644 - val_precision: 0.0240 - val_recall: 1.0000 - val_auc: 0.1149 - val_f1score: 0.0469\n",
      "Epoch 32/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 228.9590 - accuracy: 0.5695 - precision: 0.0405 - recall: 0.9643 - auc: 0.6035 - f1score: 0.0777 - val_loss: 245.4138 - val_accuracy: 0.9315 - val_precision: 0.1818 - val_recall: 0.6667 - val_auc: 0.9698 - val_f1score: 0.2857\n",
      "Epoch 33/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 226.0627 - accuracy: 0.5393 - precision: 0.0353 - recall: 0.8929 - auc: 0.5398 - f1score: 0.0679 - val_loss: 244.1016 - val_accuracy: 0.6027 - val_precision: 0.0339 - val_recall: 0.6667 - val_auc: 0.6216 - val_f1score: 0.0645\n",
      "Epoch 34/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 222.7516 - accuracy: 0.7112 - precision: 0.0573 - recall: 0.9286 - auc: 0.7610 - f1score: 0.1079 - val_loss: 256.0883 - val_accuracy: 0.1096 - val_precision: 0.0226 - val_recall: 1.0000 - val_auc: 0.0913 - val_f1score: 0.0441\n",
      "Epoch 35/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 220.1499 - accuracy: 0.4298 - precision: 0.0309 - recall: 0.9643 - auc: 0.4038 - f1score: 0.0598 - val_loss: 240.1247 - val_accuracy: 0.3973 - val_precision: 0.0330 - val_recall: 1.0000 - val_auc: 0.4145 - val_f1score: 0.0638\n",
      "Epoch 36/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 216.8379 - accuracy: 0.8482 - precision: 0.1102 - recall: 1.0000 - auc: 0.9172 - f1score: 0.1986 - val_loss: 234.7406 - val_accuracy: 0.7123 - val_precision: 0.0465 - val_recall: 0.6667 - val_auc: 0.7880 - val_f1score: 0.0870\n",
      "Epoch 37/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 214.2299 - accuracy: 0.7152 - precision: 0.0580 - recall: 0.9286 - auc: 0.7691 - f1score: 0.1092 - val_loss: 232.9169 - val_accuracy: 0.6027 - val_precision: 0.0339 - val_recall: 0.6667 - val_auc: 0.6500 - val_f1score: 0.0645\n",
      "Epoch 38/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 211.6315 - accuracy: 0.4574 - precision: 0.0324 - recall: 0.9643 - auc: 0.4532 - f1score: 0.0626 - val_loss: 233.4397 - val_accuracy: 0.3699 - val_precision: 0.0316 - val_recall: 1.0000 - val_auc: 0.3652 - val_f1score: 0.0612\n",
      "Epoch 39/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 208.7439 - accuracy: 0.7905 - precision: 0.0824 - recall: 1.0000 - auc: 0.8625 - f1score: 0.1522 - val_loss: 227.0570 - val_accuracy: 0.6849 - val_precision: 0.0426 - val_recall: 0.6667 - val_auc: 0.7703 - val_f1score: 0.0800\n",
      "Epoch 40/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 206.1771 - accuracy: 0.6857 - precision: 0.0547 - recall: 0.9643 - auc: 0.7389 - f1score: 0.1034 - val_loss: 224.4286 - val_accuracy: 0.7329 - val_precision: 0.0500 - val_recall: 0.6667 - val_auc: 0.8249 - val_f1score: 0.0930\n",
      "Epoch 41/50\n",
      "47/47 [==============================] - 65s 1s/step - loss: 203.5523 - accuracy: 0.8281 - precision: 0.0986 - recall: 1.0000 - auc: 0.8862 - f1score: 0.1795 - val_loss: 221.6278 - val_accuracy: 0.8288 - val_precision: 0.0769 - val_recall: 0.6667 - val_auc: 0.8968 - val_f1score: 0.1379\n",
      "Epoch 42/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 201.0630 - accuracy: 0.8422 - precision: 0.1034 - recall: 0.9643 - auc: 0.9094 - f1score: 0.1869 - val_loss: 221.7896 - val_accuracy: 0.5411 - val_precision: 0.0429 - val_recall: 1.0000 - val_auc: 0.5382 - val_f1score: 0.0822\n",
      "Epoch 43/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 198.9477 - accuracy: 0.6541 - precision: 0.0482 - recall: 0.9286 - auc: 0.6869 - f1score: 0.0917 - val_loss: 218.8752 - val_accuracy: 0.5616 - val_precision: 0.0448 - val_recall: 1.0000 - val_auc: 0.5772 - val_f1score: 0.0857\n",
      "Epoch 44/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 196.6900 - accuracy: 0.5648 - precision: 0.0401 - recall: 0.9643 - auc: 0.5709 - f1score: 0.0769 - val_loss: 218.2289 - val_accuracy: 0.4726 - val_precision: 0.0375 - val_recall: 1.0000 - val_auc: 0.4687 - val_f1score: 0.0723\n",
      "Epoch 45/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 194.2256 - accuracy: 0.6588 - precision: 0.0506 - recall: 0.9643 - auc: 0.6888 - f1score: 0.0961 - val_loss: 217.0809 - val_accuracy: 0.4247 - val_precision: 0.0345 - val_recall: 1.0000 - val_auc: 0.4043 - val_f1score: 0.0667\n",
      "Epoch 46/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 192.3266 - accuracy: 0.5151 - precision: 0.0349 - recall: 0.9286 - auc: 0.5117 - f1score: 0.0672 - val_loss: 210.7450 - val_accuracy: 0.7397 - val_precision: 0.0513 - val_recall: 0.6667 - val_auc: 0.8143 - val_f1score: 0.0952\n",
      "Epoch 47/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 189.6436 - accuracy: 0.8026 - precision: 0.0844 - recall: 0.9643 - auc: 0.8677 - f1score: 0.1552 - val_loss: 209.0332 - val_accuracy: 0.6370 - val_precision: 0.0370 - val_recall: 0.6667 - val_auc: 0.7486 - val_f1score: 0.0702\n",
      "Epoch 48/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 187.4234 - accuracy: 0.7696 - precision: 0.0755 - recall: 1.0000 - auc: 0.8349 - f1score: 0.1404 - val_loss: 208.1050 - val_accuracy: 0.5753 - val_precision: 0.0317 - val_recall: 0.6667 - val_auc: 0.6202 - val_f1score: 0.0606\n",
      "Epoch 49/50\n",
      "47/47 [==============================] - 67s 1s/step - loss: 185.3392 - accuracy: 0.7206 - precision: 0.0611 - recall: 0.9643 - auc: 0.7860 - f1score: 0.1149 - val_loss: 208.0084 - val_accuracy: 0.3973 - val_precision: 0.0330 - val_recall: 1.0000 - val_auc: 0.4023 - val_f1score: 0.0638\n",
      "Epoch 50/50\n",
      "47/47 [==============================] - 66s 1s/step - loss: 183.1881 - accuracy: 0.8415 - precision: 0.1031 - recall: 0.9643 - auc: 0.9169 - f1score: 0.1862 - val_loss: 201.9884 - val_accuracy: 0.7740 - val_precision: 0.0588 - val_recall: 0.6667 - val_auc: 0.8600 - val_f1score: 0.1081\n",
      "6/6 [==============================] - 5s 774ms/step - loss: 203.7953 - accuracy: 0.8132 - precision: 0.0312 - recall: 0.2500 - auc: 0.8820 - f1score: 0.0556 \n",
      "loss  =  203.79530334472656\n",
      "accuracy  =  0.8131868243217468\n",
      "precision  =  0.03125\n",
      "recall  =  0.25\n",
      "auc  =  0.8820192217826843\n",
      "f1score  =  0.0555555559694767\n",
      "True (-)ves:  147 \n",
      "False (+)ves:  31 \n",
      "False (-)ves:  3 \n",
      "True (+)ves:  1\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAApEAAAJVCAYAAACGUq5pAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAow0lEQVR4nO3deditdV0v/vdng4CIgoCSAgpHUUPKiZwlhEpQCytz4hQlRoMNRy2H6kTacKrT75hZaRgqHhWxMscOoqSpBcoQDuBEjiAIyCAqKODn98e6tz3s9rOeZz3e+xn2er287muve1j3/V17e3F9rvd3uKu7AwAAs9i01g0AAGDjUUQCADAzRSQAADNTRAIAMDNFJAAAM1NEAgAwM0UkbGeq6rZV9baquq6q/u67uM+xVXXGmG1bK1X1qKr65Fq3A2B7ooiENVJVT6uqc6vqa1V1WVX9v6p65Ai3fmKSfZLs1d0/tdKbdPfruvtHRmjPNlVVXVX3nHZNd7+/u++9Wm3amqo6sqo+UVXfqKr3VNXdp1z7uaq6Yfj/xte2LOar6llVdXlVfbWqXllVO2/7XwBwa4pIWANV9ewkf57kjzIp+O6W5K+THDPC7e+e5FPdffMI99rwqmrHddCGvZO8Kcn/TLJnknOTnLbE1360u3cbtu8U81X1mCTPT3JkJv/W/y3JC7dJwwGmUETCKquq3ZO8KMkzu/tN3f317r6pu9/W3b85XLNzVf15VX1p2P58c9pUVYdX1SVV9ZyqumJIMX9uOPfCJL+b5MlDgnV8Vf1eVb12wfMPGNK7HYf9n62qz1TV9VX12ao6dsHxDyz43sOr6pyhm/ycqnr4gnPvrarfr6p/He5zxlA4be33b27/cxe0/wlV9diq+lRVXV1Vv7Xg+gdX1VlVde1w7V9W1U7DufcNl314+L1PXnD/51XV5UletfnY8J17DM944LB/16q6sqoOX6S9n6uqF1TVRVV1TVW9qqp2Wf6/eJLkJ5Jc2N1/1903Jvm9JPerqvvMeJ8kOS7Jyd19YXdfk+T3k/zsCu4D8F1RRMLqe1iSXZL845RrfjvJQ5PcP8n9kjw4ye8sOP89SXZPsm+S45P8VVXdsbtPzCTdPG1IsE6e1pCqul2Sv0hydHffPsnDk1ywlev2TPKO4dq9kvyfJO+oqr0WXPa0JD+X5M5JdkryG1Me/T2Z/B3sm0nR+4ok/z3Jg5I8Ksn/rKoDh2tvSfKsJHtn8nd3ZJJfTpLuPmy45n7D7z1twf33zCSpO2Hhg7v7P5I8L8lrq2rXJK9Kckp3v3dKe49N8pgk90hyrwz/FlV1t6G4XWx72vD9+yb58II2fD3JfwzHF/O6obg9o6rut+D4re41fN5ni38LgG1OEQmrb68kVy3R3Xxskhd19xXdfWUm3ZU/veD8TcP5m7r7n5J8LclKx/x9O8khVXXb7r6suy/cyjWPS/Lp7v6/3X1zd5+a5BNJfnTBNa/q7k919w1J3phJAbyYm5L8YXfflOQNmRSIL+nu64fnX5RJ8ZzuPq+7zx6e+7kkf5PkB5fxm07s7m8O7bmV7n5FkouTfDDJXTIp2qf5y+7+YndfneQPkzx1uM8XunuPKdvrh+/vluS6Le55XZLbL/K8Y5MckEkR/J4k76yqPRa51+bPi90LYJtQRMLq+0qSvZcYq3fXJJ9fsP/54dh37rFFEfqNTIqLmQyJ2JOT/GKSy6rqHYt0sW7Zns1t2nfB/uUztOcr3X3L8HlzkfflBedv2Pz9qrpXVb1980SSTJLWrXaVL3Dl0G08zSuSHJLkpd39zSWu/eKCz1v+WyzH15LcYYtjd0hy/dYu7u5/7e4buvsb3f2/klybSUK7tXtt/rzVewFsK4pIWH1nJflmkidMueZLmaRQm91tOLYSX0+y64L971l4srvf2d0/nEki94lMiqul2rO5TZeusE2zeFkm7Tqou++Q5LeS1BLf6Wknq2q3TCY2nZzk94bu+mn2X/D5O/8WQ3f216Zsxw7fuTBDsjp873aZdI1vLfVd7Pds/s23utfw+cvd/ZVl3gtgFIpIWGXdfV0m4wD/aphQsmtV3aaqjq6qPx0uOzXJ71TVnYYJKr+b5LWL3XMJFyQ5bCh4dk/ygs0nqmqfqjpmKGq+mUnK9e2t3OOfktyrJssS7VhVT05ycJK3r7BNs7h9kq8m+dqQkv7SFue/nMkM5Vm8JMm53f2MTMZ6vnyJ659ZVfsNxeZvZ5hZPXRn7zZle93w/X/MZMjATw6Tcn43yUe6+xNbPmj4d3pEVe1UVbtU1W9mkrz+63DJa5IcX1UHD13cv5Pk1TP+foDvmiIS1kB3/39Jnp1JAXBlJt2lv5LkzcMlf5DJMjAfSfLRJOcPx1byrHdlUvR8JMl5uXXht2lox5eSXJ3JWMMti7QMKdfjkzwnk+745yZ5fHdftZI2zeg3Mpm0c30mKemWS+P8XpJThoksT1rqZlV1TJKj8p+/89lJHrggNdya1yc5I8lnMpkQM9O/xTCu9SczGU95TZKHJHnKgja9vKo2F7K3zyR9vSaTpPeoTCY+fWW41+lJ/jSTsZJfyKR7/cRZ2gMwhuqe2usDMNeq6nNJntHd717rtgCsJ5JIAABmtuZvcgAA2B7scIe7d9/8X1YV22b6hivf2d1HrdoDt6CIBJiiuw9Y6zYAG0PffEN2vveSQ7NHc+MFf7XUcmfblO5sAABmJokEABhFJTU/+dyqF5G14227dvJ2LmBp97nnvktfBJDk4x+94KruvtNat2OerH4RudPtV3W8ALBxve7Nf7TWTQA2iAcesPuWr2ZdfZWklnqh1vZjfjJXAABGY0wkAMBY5mhM5Pz8UgAARiOJBAAYizGRAACwOEkkAMAo5mudyPn5pQAAjEYSCQAwFmMiAQBgcYpIAABmpjsbAGAMFRNrAABgGkkkAMAoysQaAACYRhIJADAWYyIBAGBxikgAgLFUrd62ZFPqlVV1RVV9bCvnnlNVXVV7D/tVVX9RVRdX1Ueq6oFL3V8RCQCwfXp1kqO2PFhV+yf5kSRfWHD46CQHDdsJSV621M0VkQAAo6jJmMjV2pbQ3e9LcvVWTr04yXOT9IJjxyR5TU+cnWSPqrrLtPsrIgEA5kRVHZPk0u7+8Ban9k3yxQX7lwzHFmV2NgDAGCqrvU7k3lV17oL9k7r7pMUurqpdk/xWJl3Z3zVFJADAxnRVdx86w/X3SHJgkg/XpNjdL8n5VfXgJJcm2X/BtfsNxxaliAQAGMs6Xieyuz+a5M6b96vqc0kO7e6rquqtSX6lqt6Q5CFJruvuy6bdb/3+UgAAVqyqTk1yVpJ7V9UlVXX8lMv/Kclnklyc5BVJfnmp+0siAQBGUesqiezupy5x/oAFnzvJM2e5//r5pQAAbBiKSAAAZqY7GwBgLJtWdYmfNSWJBABgZpJIAIAxVNbVxJptbX5+KQAAo5FEAgCMZXVfe7imJJEAAMxMEgkAMIr1tdj4tjY/vxQAgNFIIgEAxmJMJAAALE4SCQAwFmMiAQBgcZJIAIAxVBkTCQAA00giAQDGYkwkAAAsThIJADAWYyIBAGBxikgAAGamOxsAYBRlYg0AAEwjiQQAGIuJNQAAsDhJJADAGCrGRAIAwDSSSACAUZidDQAAU0kiAQDGYnY2AAAsThIJADAWYyIBAGBxkkgAgLEYEwkAAIuTRAIAjKGsEwkAAFMpIgEAmJnubACAsZhYAwAAi5NEAgCMpCSRAACwOEkkAMAIKpJIAACYShIJADCGGrY5IYkEAGBmkkgAgFGUMZEAADCNJBIAYCSSSAAAmEISCQAwEkkkAABMIYkEABiJJBIAAKZQRAIAMDPd2QAAY/DaQwAAmE4SCQAwgvLaQwAAmE4SCQAwEkkkAABMIYkEABiJJBIAAKaQRAIAjEQSCQAAU0giAQDG4I01AABsdFX1yqq6oqo+tuDY/66qT1TVR6rqH6tqjwXnXlBVF1fVJ6vqMUvdXxEJADCSqlq1bRleneSoLY69K8kh3f39ST6V5AVDuw9O8pQk9x2+89dVtcO0mysiAQC2Q939viRXb3HsjO6+edg9O8l+w+djkryhu7/Z3Z9NcnGSB0+7vzGRAAAj2IDvzn56ktOGz/tmUlRudslwbFGKSACAjWnvqjp3wf5J3X3Scr5YVb+d5OYkr1vpwxWRAAAb01XdfeisX6qqn03y+CRHdncPhy9Nsv+Cy/Ybji3KmEgAgJGss4k1W2vfUUmem+THuvsbC069NclTqmrnqjowyUFJPjTtXpJIAIDtUFWdmuTwTLq9L0lyYiazsXdO8q6hED27u3+xuy+sqjcmuSiTbu5ndvct0+6viAQAGMs6mlfT3U/dyuGTp1z/h0n+cLn3150NAMDMJJEAAGOobLQlfr4rkkgAAGYmiQQAGIkkEgAAppBEAgCMRBIJAABTSCIBAEZQWfmbZDYiSSQAADOTRAIAjGV+gkhJJAAAs5NEAgCMwRtrAABgOkUkAAAz050NADAS3dkAADCFJBIAYCSSSAAAmEISCQAwlvkJIiWRAADMThIJADASYyIBAGAKSSQAwAiqShIJAADTSCJZFS8/8dgcfdghufLq63PoT/3Rrc79+k8fkT9+9k9kv0c/L1+59ut51s8cmSc/9geSJDvusCn3OfB7sv8Rz881X/3GWjQdWCPfvPHGPOPJR+db3/xWbrnl5hx59DH5pWf/Vt5wykl5/Sv/Opd8/rM58/zP5I577rXWTYXvmKckUhHJqvi/bzs7Lz/tX/K3v/8ztzq+3z575MiHfm++cNnV3zn24tecmRe/5swkyWMPOyS/euyjFZAwh3baeef8zevfll1vt1tuuummHP/Ex+QRh/9w7v+gh+SwIx6Tn3/K49e6iTDXdGezKv71/P/I1df910LwT3/jJ/PbL3lzunur33vSUYfmjaeft62bB6xDVZVdb7dbkuTmm2/KzTfflKrKfQ65X+66/93XuHWwdZvHRa7GttYUkayZxx/+ffnSFdfmo5+6dKvnb7vLbfLDD//evPnMC1a3YcC6ccstt+QpRz8yP/Sge+Yhj3x0vu8Bh651k4CBIpI1cdtdbpPnPv0xedHL3rHoNY877Pty1gWf0ZUNc2yHHXbIG/7fB3L6WRflwg+fn4s/edFaNwmmq1Xc1pgikjXx3/a7U+6+71750GkvyCfe8cLse+c9ctbrn5d99rr9d675qcc8KH+nKxtIcvvd98ihD3tU/u1f3r3WTQEGikjWxIUXfyl3P/IFuc/jTsx9HndiLr3i2jzsaX+SL3/l+iTJHXbbJY980D3ztvd+ZI1bCqyVa75yVa6/7tokyY033pCzP/CeHHCPe61to4DvUESyKk75Xz+b957ynNzr7vvk4tN/P8c94WFTr/+xR98vZ579iXzjxm+tUguB9ebKKy7PCU99fJ501MPz0z/26Dz0kY/OYUcelVNf9fIc9dDvzRWXX5onH/XwvOh5v7LWTYXvmKeJNbXYrNhRH1J1QpITkiS32e1Bu9z3uG3+TGDj+7c3/9HSFwEkeeABu5/X3Ws682rnfQ7qfY99yao977Mvftya/uZVWSeyu09KclKSbNr1ztu+agUAWG01X4uN684GAGBm3lgDADCCSjJHQaQkEgCA2UkiAQBGsT5mTa8WSSQAADOTRAIAjGSOgkhJJAAAs5NEAgCMxJhIAACYQhIJADCGMiYSAACmkkQCAIygkmzaND9RpCQSAICZKSIBAJiZ7mwAgJGYWAMAAFNIIgEARmKxcQAAmEISCQAwBouNAwDAdJJIAIARVIyJBACAqSSRAACjKEkkAABMI4kEABjJHAWRkkgAAGYniQQAGIkxkQAAMIUkEgBgDN5YAwAA0ykiAQCYmSISAGAEm197uFrbku2pemVVXVFVH1twbM+qeldVfXr4847D8aqqv6iqi6vqI1X1wKXur4gEANg+vTrJUVsce36SM7v7oCRnDvtJcnSSg4bthCQvW+rmikgAgJFUrd62lO5+X5Krtzh8TJJThs+nJHnCguOv6Ymzk+xRVXeZdn9FJADA/Ninuy8bPl+eZJ/h875JvrjgukuGY4uyxA8AwEhWebHxvavq3AX7J3X3Scv9cnd3VfVKH66IBADYmK7q7kNn/M6Xq+ou3X3Z0F19xXD80iT7L7huv+HYonRnAwCMZD2NiVzEW5McN3w+LslbFhz/mWGW9kOTXLeg23urJJEAANuhqjo1yeGZdHtfkuTEJH+c5I1VdXySzyd50nD5PyV5bJKLk3wjyc8tdX9FJADAGGrVx0RO1d1PXeTUkVu5tpM8c5b7684GAGBmkkgAgBFM3liz1q1YPZJIAABmJokEABjF8t5pvb2QRAIAMDNJJADASOYoiJREAgAwO0UkAAAz050NADASE2sAAGAKSSQAwBjKxBoAAJhKEgkAMILJaw/nJ4qURAIAMDNJJADASCSRAAAwhSQSAGAkcxRESiIBAJidJBIAYCTGRAIAwBSSSACAMXhjDQAATCeJBAAYQaWMiQQAgGkUkQAAzEx3NgDASOaoN1sSCQDA7CSRAAAj2TRHUaQkEgCAmUkiAQBGMkdBpCQSAIDZSSIBAEZQFYuNAwDANJJIAICRbJqfIFISCQDA7CSRAAAjMSYSAACmkEQCAIxkjoJISSQAALOTRAIAjKCSVOYnipREAgAwM0kkAMBIrBMJAABTKCIBAJiZ7mwAgDFUWWwcAACmkUQCAIxkjoJISSQAALOTRAIAjKCSbJqjKFISCQDAzCSRAAAjmaMgUhIJAMDsJJEAACOxTiQAAEwhiQQAGEGVMZEAADCVJBIAYCTWiQQAgCkkkQAAI5mfHFISCQDACigiAQCYme5sAICRWGwcAACmkEQCAIygkmyanyBy8SKyqq5P0pt3hz97+NzdfYdt3DYAANapRYvI7r79ajYEAGBDqzImcktV9ciq+rnh895VdeC2bRYAAN+NqnpWVV1YVR+rqlOrapeqOrCqPlhVF1fVaVW100rvv2QRWVUnJnlekhcMh3ZK8tqVPhAAYHtVtXrb9HbUvkl+Lcmh3X1Ikh2SPCXJnyR5cXffM8k1SY5f6W9dThL540l+LMnXk6S7v5REVzcAwPq2Y5LbVtWOSXZNclmSI5L8/XD+lCRP+G5uvpRvdXdXVSdJVd1upQ8DANierZcxkd19aVX9WZIvJLkhyRlJzktybXffPFx2SZJ9V/qM5SSRb6yqv0myR1X9fJJ3J3nFSh8IAMAo9q6qcxdsJ2w+UVV3THJMkgOT3DXJ7ZIcNebDl0wiu/vPquqHk3w1yb2S/G53v2vMRgAAbHRrsE7kVd196CLnfijJZ7v7yiSpqjcleUQmoeCOQxq5X5JLV/rw5S42/tEkt81knciPrvRhAACsii8keWhV7ZpJd/aRSc5N8p4kT0zyhiTHJXnLSh+wnNnZz0jyoSQ/MTz07Kp6+kofCACwvaphrcjV2Kbp7g9mMoHm/EwCwE1JTspkxZ1nV9XFSfZKcvJKf+tyksjfTPKA7v7K8JezV5J/S/LKlT4UAIBtq7tPTHLiFoc/k+TBY9x/OUXkV5Jcv2D/+uEYAAALrI+52atj2ruznz18vDjJB6vqLZmMiTwmyUdWoW0AAKxT05LIzQuK/8ewbbbiAZgAAGwfFi0iu/uFq9kQAICNrCrZtE4WG18NS46JrKo7JXlukvsm2WXz8e4+Yhu2CwCAdWw5b6x5XZJPZLLi+QuTfC7JOduwTQAAG1LV6m1rbTlF5F7dfXKSm7r7X7r76Zm8vBsAgDm1nCV+bhr+vKyqHpfkS0n23HZNAgDYmJZaBHx7spwi8g+qavckz0ny0iR3SPKsbdoqAADWtSWLyO5++/DxuiSP3rbNAQDYuOYoiJy62PhLM1lcfKu6+9e2SYsAAFj3piWR565aKwAANrhKWScySbr7lNVsCAAAG8dyJtYAALCUdbJ+42pZzjqRAABwK5JIAICRWCcy22529v2/9255/1kvXclXgTmzw6b5+Y8xwEZjdjYAwEjmaZyg2dkAAMxsyTGRVXWnJM9LcnCSXTYf7+4jtmG7AABYx5aTur4uyceTHJjkhUk+l+ScbdgmAIANpzKZWLNa21pbThG5V3efnOSm7v6X7n56EikkAMAcW84SPzcNf15WVY9L8qUke267JgEAbEzztKjEcorIP6iq3ZM8J8lLk9whybO2aasAAFjXliwiu/vtw8frkjx62zYHAGDjkkQuUFWvylYWHR/GRgIAMIeW05399gWfd0ny45mMiwQAYFDltYe30t3/sHC/qk5N8oFt1iIAANa95SSRWzooyZ3HbggAwEZnTOQCVXV9bj0m8vJM3mADAMCcWk539u1XoyEAABvdHA2JXPqNNVV15nKOAQAwPxZNIqtqlyS7Jtm7qu6YySshk8li4/uuQtsAADaMSrJpjqLIad3Zv5DkfyS5a5Lz8p9F5FeT/OW2bRYAAOvZokVkd78kyUuq6le7+6Wr2CYAgA1pyXGC25Hl/NZvV9Uem3eq6o5V9cvbrkkAAKx3yykif767r928093XJPn5bdYiAADWveUsNr5DVVV3d5JU1Q5Jdtq2zQIA2HjmaF7NsorI05OcVlV/M+z/wnAMAIA5tZwi8nlJTkjyS8P+u5K8Ypu1CABgA6qquVriZ8kxkd397e5+eXc/sbufmOSiJGZrAwDMseUkkamqByR5apInJflskjdty0YBAGxEcxRETn1jzb0yKRyfmuSqJKclqe5+9Cq1DQCAdWpaEvmJJO9P8vjuvjhJqupZq9IqAIANaNMcJZHTxkT+RJLLkrynql5RVUfmP199CADAHJv22sM3J3lzVd0uyTGZvEf7zlX1siT/2N1nrEoLAQA2gErMzl6ou7/e3a/v7h9Nsl+Sf89k2R8AAObUsmZnbza88vCkYQMAYIE5CiKX9e5sAAC4lZmSSAAAFlFmZwMAwFSSSACAkdQcrYYoiQQAYGaKSAAAZqY7GwBgBJPFxte6FatHEgkAwMwkkQAAI5FEAgDAFJJIAICR1By991ASCQDAzCSRAAAjMDsbAACWIIkEABhDJXM0JFISCQDA7CSRAAAj2TRHUaQkEgBgO1RVe1TV31fVJ6rq41X1sKras6reVVWfHv6840rvr4gEABjB5tnZq7Utw0uSnN7d90lyvyQfT/L8JGd290FJzhz2V0QRCQCwnamq3ZMcluTkJOnub3X3tUmOSXLKcNkpSZ6w0mcYEwkAMJJ1NCTywCRXJnlVVd0vyXlJfj3JPt192XDN5Un2WekDJJEAABvT3lV17oLthAXndkzywCQv6+4HJPl6tui67u5O0it9uCQSAGBjuqq7D13k3CVJLunuDw77f59JEfnlqrpLd19WVXdJcsVKHy6JBAAYRWXTKm7TdPflSb5YVfceDh2Z5KIkb01y3HDsuCRvWemvlUQCAGyffjXJ66pqpySfSfJzmQSIb6yq45N8PsmTVnpzRSQAwAgq62piTbr7giRb6+4+coz7684GAGBmkkgAgDEsfxHw7YIkEgCAmUkiAQBGsmk9DYrcxiSRAADMTBIJADCC9TY7e1uTRAIAMDNJJADASIyJBACAKSSRAAAjmaMgUhIJAMDsJJEAACOozFc6N0+/FQCAkSgiAQCYme5sAIAxVFJzNLNGEgkAwMwkkQAAI5mfHFISCQDACkgiAQBGUPHaQwAAmEoSCQAwkvnJISWRAACsgCQSAGAkczQkUhIJAMDsJJEAAKMob6wBAIBpJJEAACOozFc6N0+/FQCAkUgiAQBGYkwkAABMoYgEAGBmurMBAEYyP53ZkkgAAFZAEgkAMIYysQYAAKaSRAIAjMBi4wAAsARJJADASIyJBACAKSSRAAAjmZ8cUhIJAMAKSCIBAEYyR0MiJZEAAMxOEgkAMILJOpHzE0VKIgEAmJkkEgBgJMZEAgDAFIpIAABmpjsbAGAUlTKxBgAAFieJBAAYiYk1AAAwhSQSAGAEFhsHAIAlSCIBAMZQxkQCAMBUkkgAgJFIIgEAYApJJADASLyxBgAAppBEAgCMoJJsmp8gUhIJAMDsJJEAACMxJhIAAKaQRAIAjMQ6kQAAMIUiEgBgO1VVO1TVv1fV24f9A6vqg1V1cVWdVlU7rfTeikgAgJHUKv5vmX49yccX7P9Jkhd39z2TXJPk+JX+VkUkAMB2qKr2S/K4JH877FeSI5L8/XDJKUmesNL7KyJZUzfeeGN+8BEPyUMPvX8Ovf8h+YMXnbjWTQLWqV94xtNzt7veOQ+6/yFr3RTYqs2Lja/Wtgx/nuS5Sb497O+V5NruvnnYvyTJviv9vYpI1tTOO++cd7zzzJx97gU565x/z7vPeGc+9MGz17pZwDr008f9bN7y9tPXuhmwnuxdVecu2E7YfKKqHp/kiu4+b1s93BI/rKmqym677ZYkuemmm3LTTTel5ml9BGDZHvmow/L5z31urZsBU8w0VnEMV3X3oYuce0SSH6uqxybZJckdkrwkyR5VteOQRu6X5NKVPlwSyZq75ZZb8rAfeEAO3G+fHHHkD+UHHvyQtW4SAGxo3f2C7t6vuw9I8pQk/9zdxyZ5T5InDpcdl+QtK32GIpI1t8MOO+Ssc/49n/zMF3Puuefkwgs/ttZNAoDZ1WSx8dXaVuh5SZ5dVRdnMkby5JXeSHc268Yee+yRw37w8Lz7nafnvvc1cB4AxtDd703y3uHzZ5I8eIz7SiJZU1deeWWuvfbaJMkNN9yQfz7z3bnXve+zto0CgBWqVdzWmiKSNfXlyy/LY3/kiDzkQffLYQ9/cI448ody9OMev9bNAtahn/nvT83hj3pYPvXJT+YeB+yXV79yxb1wwAhWpTt7mHJ+QpLsf7e7rcYj2SAO+b7vz7996Py1bgawAbzmtaeudRNgqsk6keshI1wdq5JEdvdJ3X1odx+69953Wo1HAgCwDZlYAwAwkvnJIY2JBABgBSSRAABjmaMoUhIJAMDMFJEAAMxMdzYAwEhqjvqzJZEAAMxMEgkAMJI5WmtcEgkAwOwkkQAAI5mjIFISCQDA7CSRAABjmaMoUhIJAMDMJJEAACOoWCcSAACmkkQCAIyhrBMJAABTSSIBAEYyR0GkJBIAgNlJIgEAxjJHUaQkEgCAmSkiAQCYme5sAIBRlMXGAQBgGkkkAMBILDYOAABTSCIBAEZQmasVfiSRAADMThIJADCWOYoiJZEAAMxMEgkAMBLrRAIAwBSSSACAkVgnEgAAppBEAgCMZI6CSEkkAACzk0QCAIxhzl5ZI4kEAGBmikgAAGamOxsAYCQWGwcAgCkkkQAAI6hYbBwAAKaSRAIAjGSOgkhJJAAAs5NEAgCMZY6iSEkkAAAzk0QCAIzEOpEAADCFJBIAYCTWiQQAgCkkkQAAI5mjIFISCQDA7CSRAABjmaMoUhIJAMDMFJEAAMxMdzYAwAgqFhsHAICpJJEAAGMoi40DAMBUkkgAgJHMURApiQQA2N5U1f5V9Z6quqiqLqyqXx+O71lV76qqTw9/3nGlz1BEAgCMpVZxm+7mJM/p7oOTPDTJM6vq4CTPT3Jmdx+U5Mxhf0UUkQAA25nuvqy7zx8+X5/k40n2TXJMklOGy05J8oSVPsOYSACAUdS6XCeyqg5I8oAkH0yyT3dfNpy6PMk+K72vIhIAYGPau6rOXbB/UneftPCCqtotyT8k+R/d/dVasAZRd3dV9UofrogEABjJKq8TeVV3H7rYyaq6TSYF5Ou6+03D4S9X1V26+7KqukuSK1b6cGMiAQC2MzWJHE9O8vHu/j8LTr01yXHD5+OSvGWlz5BEAgCMYHmTplfNI5L8dJKPVtUFw7HfSvLHSd5YVccn+XySJ630AYpIAIDtTHd/IIvXtEeO8QxFJADAWNZRFLmtGRMJAMDMFJEAAMxMdzYAwEjW42Lj24okEgCAmUkiAQBGssqLja8pSSQAADOTRAIAjGSOgkhJJAAAs5NEAgCMoYyJBACAqSSRAACjmZ8oUhIJAMDMJJEAACOoGBMJAABTSSIBAEYyR0GkJBIAgNlJIgEARmJMJAAATKGIBABgZrqzAQBGUnM0tUYSCQDAzCSRAABjmZ8gUhIJAMDsJJEAACOZoyBSEgkAwOwkkQAAI6iy2DgAAEwliQQAGIl1IgEAYApJJADAWOYniJREAgAwO0kkAMBI5iiIlEQCADA7SSQAwEisEwkAAFMoIgEAmJnubACAUZTFxgEAYBpJJADACCom1gAAwFSKSAAAZqaIBABgZsZEAgCMxJhIAACYQhIJADAS60QCAMAUkkgAgDGUMZEAADCVJBIAYAQ1bPNCEgkAwMwkkQAAY5mjKFISCQDAzBSRAADMTHc2AMBILDYOAABTSCIBAEZisXEAAJhCEgkAMJI5CiIlkQAAzE4SCQAwljmKIiWRAADMbNWTyH8//7yrdtt50+dX+7mse3snuWqtGwFsCP57wdbcfa0bkMzXOpGrXkR2951W+5msf1V1bncfutbtANY//72A9cGYSACAEVSsEwkAAFNJIlkvTlrrBgAbhv9esC6df/5577ztbWrvVXzkmo4Nru5ey+cDALAB6c4GAGBmikjWXFUdVVWfrKqLq+r5a90eYH2qqldW1RVV9bG1bgugiGSNVdUOSf4qydFJDk7y1Ko6eG1bBaxTr05y1Fo3AphQRLLWHpzk4u7+THd/K8kbkhyzxm0C1qHufl+Sq9e6HcCEIpK1tm+SLy7Yv2Q4BgCsY4pIAABmpohkrV2aZP8F+/sNxwCAdUwRyVo7J8lBVXVgVe2U5ClJ3rrGbQIAlqCIZE11981JfiXJO5N8PMkbu/vCtW0VsB5V1alJzkpy76q6pKqOX+s2wTzzxhoAAGYmiQQAYGaKSAAAZqaIBABgZopIAABmpogEAGBmikjgO6rqlqq6oKo+VlV/V1W7fhf3enVVPXH4/LdVdfCUaw+vqoev4Bmfq6q9l3t8i2u+NuOzfq+qfmPWNgJsrxSRwEI3dPf9u/uQJN9K8osLT1bVjiu5aXc/o7svmnLJ4UlmLiIBWDuKSGAx709yzyElfH9VvTXJRVW1Q1X976o6p6o+UlW/kCQ18ZdV9cmqeneSO2++UVW9t6oOHT4fVVXnV9WHq+rMqjogk2L1WUMK+qiqulNV/cPwjHOq6hHDd/eqqjOq6sKq+tsktdSPqKo3V9V5w3dO2OLci4fjZ1bVnYZj96iq04fvvL+q7jPK3ybAdmZFqQKwfRsSx6OTnD4cemCSQ7r7s0Mhdl13/0BV7ZzkX6vqjCQPSHLvJAcn2SfJRUleucV975TkFUkOG+61Z3dfXVUvT/K17v6z4brXJ3lxd3+gqu6WyRuNvjfJiUk+0N0vqqrHJVnOG0uePjzjtknOqap/6O6vJLldknO7+1lV9bvDvX8lyUlJfrG7P11VD0ny10mOWMFfI8B2TREJLHTbqrpg+Pz+JCdn0s38oe7+7HD8R5J8/+bxjkl2T3JQksOSnNrdtyT5UlX981bu/9Ak79t8r+6+epF2/FCSg6u+EzTeoap2G57xE8N331FV1yzjN/1aVf348Hn/oa1fSfLtJKcNx1+b5E3DMx6e5O8WPHvnZTwDYO4oIoGFbuju+y88MBRTX194KMmvdvc7t7jusSO2Y1OSh3b3jVtpy7JV1eGZFKQP6+5vVNV7k+yyyOU9PPfaLf8OAPivjIkEZvXOJL9UVbdJkqq6V1XdLsn7kjx5GDN5lySP3sp3z05yWFUdOHx3z+H49Uluv+C6M5L86uadqrr/8PF9SZ42HDs6yR2XaOvuSa4ZCsj7ZJKEbrYpyeY09WmZdJN/Nclnq+qnhmdUVd1viWcAzCVFJDCrv81kvOP5VfWxJH+TSa/GPyb59HDuNUnO2vKL3X1lkhMy6Tr+cP6zO/ltSX5888SaJL+W5NBh4s5F+c9Z4i/MpAi9MJNu7S8s0dbTk+xYVR9P8seZFLGbfT3Jg4ffcESSFw3Hj01y/NC+C5Mcs4y/E4C5U9291m0AAGCDkUQCADAzRSQAADNTRAIAMDNFJAAAM1NEAgAwM0UkAAAzU0QCADAzRSQAADP7/wGyTxm+5MzXsAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = yaml.full_load(open(\"/home/ubuntu/covid-cxr/config.yml\", 'r'))\n",
    "    cfg['TRAIN']['EXPERIMENT_TYPE']\n",
    "    train_experiment(cfg=cfg, experiment=cfg['TRAIN']['EXPERIMENT_TYPE'], save_weights=True, write_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: ip-172-31-82-217\n",
      "IP Address: 172.31.82.217\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "## getting the hostname by socket.gethostname() method\n",
    "hostname = socket.gethostname()\n",
    "## getting the IP address using socket.gethostbyname() method\n",
    "ip_address = socket.gethostbyname(hostname)\n",
    "## printing the hostname and ip_address\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(f\"IP Address: {ip_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 4593), started 0:59:51 ago. (Use '!kill 4593' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-390a0dabd6f7d22e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-390a0dabd6f7d22e\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/ubuntu/covid-cxr/results/logs --host {ip_address}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
