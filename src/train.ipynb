{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train.py converted to notebook\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install dill\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install scikit-imageF\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install imblearn\n",
    "# sudo -E /opt/tljh/user/bin/pip3 install opencv-python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yaml\n",
    "import os\n",
    "import datetime\n",
    "import random\n",
    "import dill\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.summary as tf_summary\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from math import ceil\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, CategoricalAccuracy, Precision, Recall, AUC\n",
    "from tensorflow.keras.models import save_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping, TensorBoard, ReduceLROnPlateau\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorboard.plugins.hparams import api as hp\n",
    "import sys\n",
    "sys.path.append('src')\n",
    "from models.models import *\n",
    "from visualization.visualize import *\n",
    "from custom.metrics import F1Score\n",
    "from data.preprocess import remove_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 1875683932670039604\n",
      ", name: \"/device:XLA_CPU:0\"\n",
      "device_type: \"XLA_CPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 15575951257637008336\n",
      "physical_device_desc: \"device: XLA_CPU device\"\n",
      ", name: \"/device:XLA_GPU:0\"\n",
      "device_type: \"XLA_GPU\"\n",
      "memory_limit: 17179869184\n",
      "locality {\n",
      "}\n",
      "incarnation: 18293452786807977872\n",
      "physical_device_desc: \"device: XLA_GPU device\"\n",
      ", name: \"/device:GPU:0\"\n",
      "device_type: \"GPU\"\n",
      "memory_limit: 14640768640\n",
      "locality {\n",
      "  bus_id: 1\n",
      "  links {\n",
      "  }\n",
      "}\n",
      "incarnation: 4906114476970803133\n",
      "physical_device_desc: \"device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\"\n",
      "]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "print(device_lib.list_local_devices())\n",
    "import tensorflow as tf\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  1\n"
     ]
    }
   ],
   "source": [
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_class_weights(histogram, class_multiplier=None):\n",
    "    '''\n",
    "    Computes weights for each class to be applied in the loss function during training.\n",
    "    :param histogram: A list depicting the number of each item in different class\n",
    "    :param class_multiplier: List of values to multiply the calculated class weights by. For further control of class weighting.\n",
    "    :return: A dictionary containing weights for each class\n",
    "    '''\n",
    "    weights = [None] * len(histogram)\n",
    "    for i in range(len(histogram)):\n",
    "        weights[i] = (1.0 / len(histogram)) * sum(histogram) / histogram[i]\n",
    "    class_weight = {i: weights[i] for i in range(len(histogram))}\n",
    "    if class_multiplier is not None:\n",
    "        class_weight = [class_weight[i] * class_multiplier[i] for i in range(len(histogram))]\n",
    "    print(\"Class weights: \", class_weight)\n",
    "    #debug\n",
    "    print(\"Class weights type:\", type(class_weight))\n",
    "    return class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_minority_oversample(train_set):\n",
    "    '''\n",
    "    Oversample the minority class using the specified algorithm\n",
    "    :param train_set: Training set image file names and labels\n",
    "    :return: A new training set containing oversampled examples\n",
    "    '''\n",
    "    X_train = train_set[[x for x in train_set.columns if x != 'label']].to_numpy()\n",
    "    if X_train.shape[1] == 1:\n",
    "        X_train = np.expand_dims(X_train, axis=-1)\n",
    "    Y_train = train_set['label'].to_numpy()\n",
    "    sampler = RandomOverSampler(random_state=np.random.randint(0, high=1000))\n",
    "    X_resampled, Y_resampled = sampler.fit_resample(X_train, Y_train)\n",
    "    filenames = X_resampled[:, 1]     # Filename is in second column\n",
    "    label_strs = X_resampled[:, 2]    # Class name is in second column\n",
    "    print(\"Train set shape before oversampling: \", X_train.shape, \" Train set shape after resampling: \", X_resampled.shape)\n",
    "    train_set_resampled = pd.DataFrame({'filename': filenames, 'label': Y_resampled, 'label_str': label_strs})\n",
    "    return train_set_resampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(cfg, data, callbacks, verbose=1):\n",
    "    '''\n",
    "    Train a and evaluate model on given data.\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: dict of partitioned dataset\n",
    "    :param callbacks: list of callbacks for Keras model\n",
    "    :param verbose: Verbosity mode to pass to model.fit_generator()\n",
    "    :return: Trained model and associated performance metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # If set in config file, oversample the minority class\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'random_oversample':\n",
    "        data['TRAIN'] = random_minority_oversample(data['TRAIN'])\n",
    "\n",
    "    # Create ImageDataGenerators\n",
    "    train_img_gen = ImageDataGenerator(rotation_range=10, preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    val_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "    test_img_gen = ImageDataGenerator(preprocessing_function=remove_text,\n",
    "                                       samplewise_std_normalization=True, samplewise_center=True)\n",
    "\n",
    "    # Create DataFrameIterators\n",
    "    img_shape = tuple(cfg['DATA']['IMG_DIM'])\n",
    "    y_col = 'label_str'\n",
    "    class_mode = 'categorical'\n",
    "    train_generator = train_img_gen.flow_from_dataframe(dataframe=data['TRAIN'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    val_generator = val_img_gen.flow_from_dataframe(dataframe=data['VAL'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False)\n",
    "    test_generator = test_img_gen.flow_from_dataframe(dataframe=data['TEST'], directory=cfg['PATHS']['RAW_DATA'],\n",
    "        x_col=\"filename\", y_col=y_col, target_size=img_shape, batch_size=cfg['TRAIN']['BATCH_SIZE'],\n",
    "        class_mode=class_mode, validate_filenames=False, shuffle=False)\n",
    "\n",
    "    # Save model's ordering of class indices\n",
    "    dill.dump(test_generator.class_indices, open(cfg['PATHS']['OUTPUT_CLASS_INDICES'], 'wb'))\n",
    "\n",
    "    # Apply class imbalance strategy. We have many more X-rays negative for COVID-19 than positive.\n",
    "    histogram = np.bincount(np.array(train_generator.labels).astype(int))  # Get class distribution\n",
    "    class_weight = None\n",
    "    if cfg['TRAIN']['IMB_STRATEGY'] == 'class_weight':\n",
    "        class_multiplier = cfg['TRAIN']['CLASS_MULTIPLIER']\n",
    "        class_multiplier = [class_multiplier[cfg['DATA']['CLASSES'].index(c)] for c in test_generator.class_indices]\n",
    "        class_weight = get_class_weights(histogram, class_multiplier)\n",
    "\n",
    "    # Define metrics.\n",
    "    covid_class_idx = test_generator.class_indices['COVID-19']   # Get index of COVID-19 class\n",
    "    thresholds = 1.0 / len(cfg['DATA']['CLASSES'])      # Binary classification threshold for a class\n",
    "    metrics = [CategoricalAccuracy(name='accuracy'),\n",
    "               Precision(name='precision', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               Recall(name='recall', thresholds=thresholds, class_id=covid_class_idx),\n",
    "               AUC(name='auc'),\n",
    "               F1Score(name='f1score', thresholds=thresholds, class_id=covid_class_idx)]\n",
    "\n",
    "    # Define the model.\n",
    "    print('Training distribution: ', ['Class ' + list(test_generator.class_indices.keys())[i] + ': ' + str(histogram[i]) + '. '\n",
    "           for i in range(len(histogram))])\n",
    "    input_shape = cfg['DATA']['IMG_DIM'] + [3]\n",
    "    num_gpus = cfg['TRAIN']['NUM_GPUS']\n",
    "    #debug\n",
    "    print(\"******* GPU:\", num_gpus)\n",
    "    if cfg['TRAIN']['MODEL_DEF'] == 'dcnn_resnet':\n",
    "        model_def = dcnn_resnet\n",
    "    elif cfg['TRAIN']['MODEL_DEF'] == 'resnet50v2':\n",
    "        model_def = resnet50v2\n",
    "    else:\n",
    "        model_def = resnet101v2\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_BINARY'], input_shape, metrics, 2, output_bias=output_bias, gpus=num_gpus)\n",
    "    else:\n",
    "        n_classes = len(cfg['DATA']['CLASSES'])\n",
    "        histogram = np.bincount(data['TRAIN']['label'].astype(int))\n",
    "        output_bias = np.log([histogram[i] / (np.sum(histogram) - histogram[i]) for i in range(histogram.shape[0])])\n",
    "        model = model_def(cfg['NN']['DCNN_MULTICLASS'], input_shape, metrics, n_classes, output_bias=output_bias,\n",
    "                          gpus=num_gpus)\n",
    "    #debug\n",
    "    print(\"histogram type\", type(histogram), histogram)\n",
    "        \n",
    "    # Train the model.\n",
    "    steps_per_epoch = ceil(train_generator.n / train_generator.batch_size)\n",
    "    val_steps = ceil(val_generator.n / val_generator.batch_size)\n",
    "    # debug\n",
    "    print(\"***** class weight\", class_weight)\n",
    "    class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "    history = model.fit(train_generator, steps_per_epoch=steps_per_epoch, epochs=cfg['TRAIN']['EPOCHS'],\n",
    "                                  validation_data=val_generator, validation_steps=val_steps, callbacks=callbacks,\n",
    "                                  verbose=verbose, class_weight=class_weight)\n",
    "\n",
    "    # Run the model on the test set and print the resulting performance metrics.\n",
    "    test_results = model.evaluate(test_generator, verbose=1)\n",
    "    test_metrics = {}\n",
    "    test_summary_str = [['**Metric**', '**Value**']]\n",
    "    for metric, value in zip(model.metrics_names, test_results):\n",
    "        test_metrics[metric] = value\n",
    "        print(metric, ' = ', value)\n",
    "        test_summary_str.append([metric, str(value)])\n",
    "    return model, test_metrics, test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#class_weight = {0:26.589285714285715, 1:0.07643737166324435}\n",
    "#print(class_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_train(cfg, data, callbacks, base_log_dir):\n",
    "    '''\n",
    "    Trains a model a series of times and returns the model with the best test set metric (specified in cfg)\n",
    "    :param cfg: Project config (from config.yml)\n",
    "    :param data: Partitioned dataset\n",
    "    :param callbacks: List of callbacks to pass to model.fit()\n",
    "    :param base_log_dir: Base directory to write logs\n",
    "    :return: The trained Keras model with best test set performance on the metric specified in cfg\n",
    "    '''\n",
    "\n",
    "    # Load order of metric preference\n",
    "    metric_preference = cfg['TRAIN']['METRIC_PREFERENCE']\n",
    "    best_metrics = dict.fromkeys(metric_preference, 0.0)\n",
    "    if 'loss' in metric_preference:\n",
    "        best_metrics['loss'] = 100000.0\n",
    "\n",
    "    # Train NUM_RUNS models and return the best one according to the preferred metrics\n",
    "    for i in range(cfg['TRAIN']['NUM_RUNS']):\n",
    "        print(\"Training run \", i+1, \" / \", cfg['TRAIN']['NUM_RUNS'])\n",
    "        cur_callbacks = callbacks.copy()\n",
    "        cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "        if base_log_dir is not None:\n",
    "            log_dir = base_log_dir + cur_date\n",
    "            cur_callbacks.append(TensorBoard(log_dir=log_dir, histogram_freq=1))\n",
    "\n",
    "        # Train the model and evaluate performance on test set\n",
    "        new_model, test_metrics, test_generator = train_model(cfg, data, cur_callbacks, verbose=1)\n",
    "\n",
    "        # Log test set results and images\n",
    "        if base_log_dir is not None:\n",
    "            log_test_results(cfg, new_model, test_generator, test_metrics, log_dir)\n",
    "\n",
    "        # If this model outperforms the previous ones based on the specified metric preferences, save this one.\n",
    "        for i in range(len(metric_preference)):\n",
    "            if (((metric_preference[i] == 'loss') and (test_metrics[metric_preference[i]] < best_metrics[metric_preference[i]]))\n",
    "                    or ((metric_preference[i] != 'loss') and (test_metrics[metric_preference[i]] > best_metrics[metric_preference[i]]))):\n",
    "                best_model = new_model\n",
    "                best_metrics = test_metrics\n",
    "                best_generator = test_generator\n",
    "                best_model_date = cur_date\n",
    "                break\n",
    "            elif (test_metrics[metric_preference[i]] == best_metrics[metric_preference[i]]):\n",
    "                continue\n",
    "            else:\n",
    "                break\n",
    "\n",
    "    print(\"Best model test metrics: \", best_metrics)\n",
    "    return best_model, best_metrics, best_generator, best_model_date\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_hparam_search(cfg, data, callbacks, log_dir):\n",
    "    '''\n",
    "    Conduct a random hyperparameter search over the ranges given for the hyperparameters in config.yml and log results\n",
    "    in TensorBoard. Model is trained x times for y random combinations of hyperparameters.\n",
    "    :param cfg: Project config\n",
    "    :param data: Dict containing the partitioned datasets\n",
    "    :param callbacks: List of callbacks for Keras model (excluding TensorBoard)\n",
    "    :param log_dir: Base directory in which to store logs\n",
    "    :return: (Last model trained, resultant test set metrics, test data generator)\n",
    "    '''\n",
    "\n",
    "    # Define HParam objects for each hyperparameter we wish to tune.\n",
    "    hp_ranges = cfg['HP_SEARCH']['RANGES']\n",
    "    HPARAMS = []\n",
    "    HPARAMS.append(hp.HParam('KERNEL_SIZE', hp.Discrete(hp_ranges['KERNEL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('MAXPOOL_SIZE', hp.Discrete(hp_ranges['MAXPOOL_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('INIT_FILTERS', hp.Discrete(hp_ranges['INIT_FILTERS'])))\n",
    "    HPARAMS.append(hp.HParam('FILTER_EXP_BASE', hp.IntInterval(hp_ranges['FILTER_EXP_BASE'][0], hp_ranges['FILTER_EXP_BASE'][1])))\n",
    "    HPARAMS.append(hp.HParam('NODES_DENSE0', hp.Discrete(hp_ranges['NODES_DENSE0'])))\n",
    "    HPARAMS.append(hp.HParam('CONV_BLOCKS', hp.IntInterval(hp_ranges['CONV_BLOCKS'][0], hp_ranges['CONV_BLOCKS'][1])))\n",
    "    HPARAMS.append(hp.HParam('DROPOUT', hp.Discrete(hp_ranges['DROPOUT'])))\n",
    "    HPARAMS.append(hp.HParam('LR', hp.RealInterval(hp_ranges['LR'][0], hp_ranges['LR'][1])))\n",
    "    HPARAMS.append(hp.HParam('OPTIMIZER', hp.Discrete(hp_ranges['OPTIMIZER'])))\n",
    "    HPARAMS.append(hp.HParam('L2_LAMBDA', hp.Discrete(hp_ranges['L2_LAMBDA'])))\n",
    "    HPARAMS.append(hp.HParam('BATCH_SIZE', hp.Discrete(hp_ranges['BATCH_SIZE'])))\n",
    "    HPARAMS.append(hp.HParam('IMB_STRATEGY', hp.Discrete(hp_ranges['IMB_STRATEGY'])))\n",
    "\n",
    "    # Define test set metrics that we wish to log to TensorBoard for each training run\n",
    "    HP_METRICS = [hp.Metric(metric, display_name='Test ' + metric) for metric in cfg['HP_SEARCH']['METRICS']]\n",
    "\n",
    "    # Configure TensorBoard to log the results\n",
    "    with tf.summary.create_file_writer(log_dir).as_default():\n",
    "        hp.hparams_config(hparams=HPARAMS, metrics=HP_METRICS)\n",
    "\n",
    "    # Complete a number of training runs at different hparam values and log the results.\n",
    "    repeats_per_combo = cfg['HP_SEARCH']['REPEATS']   # Number of times to train the model per combination of hparams\n",
    "    num_combos = cfg['HP_SEARCH']['COMBINATIONS']     # Number of random combinations of hparams to attempt\n",
    "    num_sessions = num_combos * repeats_per_combo       # Total number of runs in this experiment\n",
    "    model_type = 'DCNN_BINARY' if cfg['TRAIN']['CLASS_MODE'] == 'binary' else 'DCNN_MULTICLASS'\n",
    "    trial_id = 0\n",
    "    for group_idx in range(num_combos):\n",
    "        rand = random.Random()\n",
    "        HPARAMS = {h: h.domain.sample_uniform(rand) for h in HPARAMS}\n",
    "        hparams = {h.name: HPARAMS[h] for h in HPARAMS}  # To pass to model definition\n",
    "        for repeat_idx in range(repeats_per_combo):\n",
    "            trial_id += 1\n",
    "            print(\"Running training session %d/%d\" % (trial_id, num_sessions))\n",
    "            print(\"Hparam values: \", {h.name: HPARAMS[h] for h in HPARAMS})\n",
    "            trial_logdir = os.path.join(log_dir, str(trial_id))     # Need specific logdir for each trial\n",
    "            callbacks_hp = callbacks + [TensorBoard(log_dir=trial_logdir, profile_batch=0, write_graph=False)]\n",
    "\n",
    "            # Set values of hyperparameters for this run in config file.\n",
    "            for h in hparams:\n",
    "                if h in ['LR', 'L2_LAMBDA']:\n",
    "                    val = 10 ** hparams[h]      # These hyperparameters are sampled on the log scale.\n",
    "                else:\n",
    "                    val = hparams[h]\n",
    "                cfg['NN'][model_type][h] = val\n",
    "\n",
    "            # Set some hyperparameters that are not specified in model definition.\n",
    "            cfg['TRAIN']['BATCH_SIZE'] = hparams['BATCH_SIZE']\n",
    "            cfg['TRAIN']['IMB_STRATEGY'] = hparams['IMB_STRATEGY']\n",
    "\n",
    "            # Run a training session and log the performance metrics on the test set to HParams dashboard in TensorBoard\n",
    "            with tf.summary.create_file_writer(trial_logdir).as_default():\n",
    "                hp.hparams(HPARAMS, trial_id=str(trial_id))\n",
    "                model, test_metrics, test_generator = train_model(cfg, data, callbacks_hp, verbose=0)\n",
    "                for metric in HP_METRICS:\n",
    "                    if metric._tag in test_metrics:\n",
    "                        tf.summary.scalar(metric._tag, test_metrics[metric._tag], step=1)   # Log test metric\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_test_results(cfg, model, test_generator, test_metrics, log_dir):\n",
    "    '''\n",
    "    Visualize performance of a trained model on the test set. Optionally save the model.\n",
    "    :param cfg: Project config\n",
    "    :param model: A trained Keras model\n",
    "    :param test_generator: A Keras generator for the test set\n",
    "    :param test_metrics: Dict of test set performance metrics\n",
    "    :param log_dir: Path to write TensorBoard logs\n",
    "    '''\n",
    "\n",
    "    # Visualization of test results\n",
    "    test_predictions = model.predict(test_generator, verbose=0)\n",
    "    test_labels = test_generator.labels\n",
    "    covid_idx = test_generator.class_indices['COVID-19']\n",
    "    plt = plot_roc(\"Test set\", test_labels, test_predictions, class_id=covid_idx)\n",
    "    roc_img = plot_to_tensor()\n",
    "    plt = plot_confusion_matrix(test_labels, test_predictions, class_id=covid_idx)\n",
    "    cm_img = plot_to_tensor()\n",
    "\n",
    "    # Log test set results and plots in TensorBoard\n",
    "    writer = tf_summary.create_file_writer(logdir=log_dir)\n",
    "\n",
    "    # Create table of test set metrics\n",
    "    test_summary_str = [['**Metric**','**Value**']]\n",
    "    thresholds = cfg['TRAIN']['THRESHOLDS']  # Load classification thresholds\n",
    "    for metric in test_metrics:\n",
    "        if metric in ['precision', 'recall'] and isinstance(metric, list):\n",
    "            metric_values = dict(zip(thresholds, test_metrics[metric]))\n",
    "        else:\n",
    "            metric_values = test_metrics[metric]\n",
    "        test_summary_str.append([metric, str(metric_values)])\n",
    "\n",
    "    # Create table of model and train config values\n",
    "    hparam_summary_str = [['**Variable**', '**Value**']]\n",
    "    for key in cfg['TRAIN']:\n",
    "        hparam_summary_str.append([key, str(cfg['TRAIN'][key])])\n",
    "    if cfg['TRAIN']['CLASS_MODE'] == 'binary':\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "    else:\n",
    "        for key in cfg['NN']['DCNN_BINARY']:\n",
    "            hparam_summary_str.append([key, str(cfg['NN']['DCNN_BINARY'][key])])\n",
    "\n",
    "    # Write to TensorBoard logs\n",
    "    with writer.as_default():\n",
    "        tf_summary.text(name='Test set metrics', data=tf.convert_to_tensor(test_summary_str), step=0)\n",
    "        tf_summary.text(name='Run hyperparameters', data=tf.convert_to_tensor(hparam_summary_str), step=0)\n",
    "        tf_summary.image(name='ROC Curve (Test Set)', data=roc_img, step=0)\n",
    "        tf_summary.image(name='Confusion Matrix (Test Set)', data=cm_img, step=0)\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_experiment(cfg=None, experiment='single_train', save_weights=True, write_logs=True):\n",
    "    '''\n",
    "    Defines and trains HIFIS-v2 model. Prints and logs relevant metrics.\n",
    "    :param experiment: The type of training experiment. Choices are {'single_train'}\n",
    "    :param save_weights: A flag indicating whether to save the model weights\n",
    "    :param write_logs: A flag indicating whether to write TensorBoard logs\n",
    "    :return: A dictionary of metrics on the test set\n",
    "    '''\n",
    "\n",
    "    # Load project config data\n",
    "    if cfg is None:\n",
    "        cfg = yaml.full_load(open(os.getcwd() + \"/config.yml\", 'r'))\n",
    "\n",
    "    # Set logs directory\n",
    "    cur_date = datetime.datetime.now().strftime('%Y%m%d-%H%M%S')\n",
    "    print(cfg['PATHS']['LOGS'])\n",
    "    log_dir = cfg['PATHS']['LOGS'] + \"training/\" + cur_date if write_logs else None\n",
    "    if not os.path.exists(cfg['PATHS']['LOGS'] + \"training\\\\\"):\n",
    "        os.makedirs(cfg['PATHS']['LOGS'] + \"training\\\\\")\n",
    "\n",
    "    # Load dataset file paths and labels\n",
    "    data = {}\n",
    "    data['TRAIN'] = pd.read_csv(cfg['PATHS']['TRAIN_SET'])\n",
    "    data['VAL'] = pd.read_csv(cfg['PATHS']['VAL_SET'])\n",
    "    data['TEST'] = pd.read_csv(cfg['PATHS']['TEST_SET'])\n",
    "\n",
    "    # Set callbacks.\n",
    "    early_stopping = EarlyStopping(monitor='val_loss', verbose=1, patience=cfg['TRAIN']['PATIENCE'], mode='min', restore_best_weights=True)\n",
    "    callbacks = [early_stopping]\n",
    "\n",
    "    # Conduct the desired train experiment\n",
    "    if experiment == 'hparam_search':\n",
    "        log_dir = cfg['PATHS']['LOGS'] + \"hparam_search\\\\\" + cur_date\n",
    "        random_hparam_search(cfg, data, callbacks, log_dir)\n",
    "    else:\n",
    "        if experiment == 'multi_train':\n",
    "            base_log_dir = cfg['PATHS']['LOGS'] + \"training\\\\\" if write_logs else None\n",
    "            model, test_metrics, test_generator, cur_date = multi_train(cfg, data, callbacks, base_log_dir)\n",
    "        else:\n",
    "            if write_logs:\n",
    "                tensorboard = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "                callbacks.append(tensorboard)\n",
    "            #\n",
    "            print(cfg)\n",
    "            print(data)\n",
    "            print(callbacks)\n",
    "            model, test_metrics, test_generator = train_model(cfg, data, callbacks)\n",
    "            if write_logs:\n",
    "                log_test_results(cfg, model, test_generator, test_metrics, log_dir)\n",
    "        if save_weights:\n",
    "            model_path = cfg['PATHS']['MODEL_WEIGHTS'] + 'model' + cur_date + '.h5'\n",
    "            save_model(model, model_path)  # Save the model's weights\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/covid-cxr/results/logs/\n",
      "{'PATHS': {'RAW_DATA': '/home/ubuntu/covid-cxr/data/', 'MILA_DATA': '/home/ubuntu/covid-cxr/data/covid-chestxray-dataset/', 'FIGURE1_DATA': '/home/ubuntu/covid-cxr/data/Figure1-COVID-chestxray-dataset/', 'RSNA_DATA': '/home/ubuntu/covid-cxr/data/rsna/', 'PROCESSED_DATA': 'data/processed/', 'TRAIN_SET': '/home/ubuntu/covid-cxr/data/processed/train_set.csv', 'VAL_SET': '/home/ubuntu/covid-cxr/data/processed/val_set.csv', 'TEST_SET': '/home/ubuntu/covid-cxr/data/processed/test_set.csv', 'IMAGES': '/home/ubuntu/covid-cxr/documents/generated_images/', 'LOGS': '/home/ubuntu/covid-cxr/results/logs/', 'MODEL_WEIGHTS': '/home/ubuntu/covid-cxr/results/models/', 'MODEL_TO_LOAD': '/home/ubuntu/covid-cxr/results/models/model20201102-033225.h5', 'LIME_EXPLAINER': '/home/ubuntu/covid-cxr/data/interpretability/lime_explainer.pkl', 'OUTPUT_CLASS_INDICES': '/home/ubuntu/covid-cxr/data/interpretability/output_class_indices.pkl', 'BATCH_PRED_IMGS': '/home/ubuntu/covid-cxr/data/processed/test/', 'BATCH_PREDS': '/home/ubuntu/covid-cxr/results/predictions/'}, 'DATA': {'IMG_DIM': [224, 224], 'VIEWS': ['PA', 'AP'], 'VAL_SPLIT': 0.08, 'TEST_SPLIT': 0.1, 'NUM_RSNA_IMGS': 1000, 'CLASSES': ['non-COVID-19', 'COVID-19']}, 'TRAIN': {'CLASS_MODE': 'binary', 'MODEL_DEF': 'dcnn_resnet', 'CLASS_MULTIPLIER': [0.15, 1.0], 'EXPERIMENT_TYPE': 'single_train', 'BATCH_SIZE': 32, 'EPOCHS': 3, 'THRESHOLDS': 0.5, 'PATIENCE': 7, 'IMB_STRATEGY': 'class_weight', 'METRIC_PREFERENCE': ['auc', 'recall', 'precision', 'loss'], 'NUM_RUNS': 10, 'NUM_GPUS': 1}, 'NN': {'DCNN_BINARY': {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}, 'DCNN_MULTICLASS': {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 4, 'NODES_DENSE0': 128, 'LR': 0.0002, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}}, 'LIME': {'KERNEL_WIDTH': 1.75, 'FEATURE_SELECTION': 'lasso_path', 'NUM_FEATURES': 1000, 'NUM_SAMPLES': 1000, 'COVID_ONLY': False}, 'HP_SEARCH': {'METRICS': ['accuracy', 'loss', 'recall', 'precision', 'auc'], 'COMBINATIONS': 50, 'REPEATS': 2, 'RANGES': {'KERNEL_SIZE': ['(3,3)', '(5,5)'], 'MAXPOOL_SIZE': ['(2,2)', '(3,3)'], 'INIT_FILTERS': [8, 16, 32], 'FILTER_EXP_BASE': [2, 3], 'NODES_DENSE0': [128, 256, 512, 1024], 'CONV_BLOCKS': [3, 8], 'DROPOUT': [0.0, 0.1, 0.2, 0.3, 0.4, 0.5], 'LR': [-5.0, -3.0], 'OPTIMIZER': ['adam'], 'L2_LAMBDA': [0.0, 1e-05, 0.0001, 0.001], 'BATCH_SIZE': [16, 32], 'IMB_STRATEGY': ['class_weight']}}, 'PREDICTION': {'THRESHOLD': 0.5}}\n",
      "{'TRAIN':       Unnamed: 0                                           filename  label  \\\n",
      "0            601  covid-chestxray-dataset/images/1-s2.0-S1341321...      0   \n",
      "1             97      rsna/02285fa4-35b7-4af6-b88f-3cac45a7f5c8.jpg      0   \n",
      "2            783       covid-chestxray-dataset/images/16497_1_1.png      0   \n",
      "3            189  covid-chestxray-dataset/images/covid-19-infect...      0   \n",
      "4            665      rsna/09629e2b-7f1e-499c-aab7-2bff196f034b.jpg      0   \n",
      "...          ...                                                ...    ...   \n",
      "1484         699      rsna/098e14d4-3205-4c2d-a059-738f830c0aa5.jpg      0   \n",
      "1485         359  covid-chestxray-dataset/images/covid-19-pneumo...      0   \n",
      "1486         347    covid-chestxray-dataset/images/extubation-8.jpg      0   \n",
      "1487         860        covid-chestxray-dataset/images/1e33b16c.jpg      0   \n",
      "1488         109      rsna/02de2d68-b7f9-428b-ac12-0cb8f56a0145.jpg      0   \n",
      "\n",
      "         label_str  \n",
      "0     non-COVID-19  \n",
      "1     non-COVID-19  \n",
      "2     non-COVID-19  \n",
      "3     non-COVID-19  \n",
      "4     non-COVID-19  \n",
      "...            ...  \n",
      "1484  non-COVID-19  \n",
      "1485  non-COVID-19  \n",
      "1486  non-COVID-19  \n",
      "1487  non-COVID-19  \n",
      "1488  non-COVID-19  \n",
      "\n",
      "[1489 rows x 4 columns], 'VAL':      Unnamed: 0                                           filename  label  \\\n",
      "0           437        covid-chestxray-dataset/images/bb0e626a.jpg      0   \n",
      "1            39      rsna/01a4059c-22f7-4f51-8a27-50aff0b3aeb3.jpg      0   \n",
      "2            72  covid-chestxray-dataset/images/7C69C012-7479-4...      0   \n",
      "3           133      rsna/03d92597-3e33-4fdf-8db5-a27cf5b8d3eb.jpg      0   \n",
      "4            37  Figure1-COVID-chestxray-dataset/images/COVID-0...      1   \n",
      "..          ...                                                ...    ...   \n",
      "141         913  covid-chestxray-dataset/images/3e9d9c9b02b9bcd...      0   \n",
      "142         508      rsna/082fd63e-aec4-401a-822b-eb10d98b562c.jpg      0   \n",
      "143         842        covid-chestxray-dataset/images/0cea09eb.jpg      0   \n",
      "144         202  covid-chestxray-dataset/images/pneumocystis-ji...      0   \n",
      "145         365      rsna/07166637-dcb4-40c0-b553-257690afa9be.jpg      0   \n",
      "\n",
      "        label_str  \n",
      "0    non-COVID-19  \n",
      "1    non-COVID-19  \n",
      "2    non-COVID-19  \n",
      "3    non-COVID-19  \n",
      "4        COVID-19  \n",
      "..            ...  \n",
      "141  non-COVID-19  \n",
      "142  non-COVID-19  \n",
      "143  non-COVID-19  \n",
      "144  non-COVID-19  \n",
      "145  non-COVID-19  \n",
      "\n",
      "[146 rows x 4 columns], 'TEST':      Unnamed: 0                                           filename  label  \\\n",
      "0           884        covid-chestxray-dataset/images/c873402e.jpg      0   \n",
      "1           442      rsna/07a16de4-9d4c-4e88-a980-37734b8a4cdd.jpg      0   \n",
      "2           967      rsna/0bbe0f92-940f-431a-b8c4-3b371ea7d9aa.jpg      0   \n",
      "3           422      rsna/07752357-2f21-4e42-9015-27886b3d5857.jpg      0   \n",
      "4           996      rsna/0bf44996-58da-4a12-8be1-da5c9b009975.jpg      0   \n",
      "..          ...                                                ...    ...   \n",
      "177         131      rsna/03cd7a5b-d5d7-40a1-81b1-c4264920530a.jpg      0   \n",
      "178         556  covid-chestxray-dataset/images/11547_2020_1200...      0   \n",
      "179         147  covid-chestxray-dataset/images/03BF7561-A9BA-4...      0   \n",
      "180         731      rsna/09d41130-fc56-4a25-96f0-862f00a790cb.jpg      0   \n",
      "181         357     covid-chestxray-dataset/images/case_76_1-3.png      0   \n",
      "\n",
      "        label_str  \n",
      "0    non-COVID-19  \n",
      "1    non-COVID-19  \n",
      "2    non-COVID-19  \n",
      "3    non-COVID-19  \n",
      "4    non-COVID-19  \n",
      "..            ...  \n",
      "177  non-COVID-19  \n",
      "178  non-COVID-19  \n",
      "179  non-COVID-19  \n",
      "180  non-COVID-19  \n",
      "181  non-COVID-19  \n",
      "\n",
      "[182 rows x 4 columns]}\n",
      "[<tensorflow.python.keras.callbacks.EarlyStopping object at 0x7f63427bb650>, <tensorflow.python.keras.callbacks.TensorBoard object at 0x7f63c648f4d0>]\n",
      "Found 1489 non-validated image filenames belonging to 2 classes.\n",
      "Found 146 non-validated image filenames belonging to 2 classes.\n",
      "Found 182 non-validated image filenames belonging to 2 classes.\n",
      "Class weights:  [26.589285714285715, 0.07643737166324435]\n",
      "Class weights type: <class 'list'>\n",
      "Training distribution:  ['Class COVID-19: 28. ', 'Class non-COVID-19: 1461. ']\n",
      "******* GPU: 1\n",
      "MODEL CONFIG:  {'KERNEL_SIZE': '(3,3)', 'STRIDES': '(1,1)', 'INIT_FILTERS': 16, 'FILTER_EXP_BASE': 3, 'MAXPOOL_SIZE': '(2,2)', 'CONV_BLOCKS': 3, 'NODES_DENSE0': 128, 'LR': 1e-05, 'OPTIMIZER': 'adam', 'DROPOUT': 0.4, 'L2_LAMBDA': 0.0001}\n",
      "Model: \"functional_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 224, 224, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv0_0 (Conv2D)                (None, 224, 224, 16) 448         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization (BatchNorma (None, 224, 224, 16) 64          conv0_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)         (None, 224, 224, 16) 0           batch_normalization[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv0_1 (Conv2D)                (None, 224, 224, 16) 2320        leaky_re_lu[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concat0 (Concatenate)           (None, 224, 224, 19) 0           conv0_1[0][0]                    \n",
      "                                                                 input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 224, 224, 19) 76          concat0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)       (None, 224, 224, 19) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D)    (None, 112, 112, 19) 0           leaky_re_lu_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv1_0 (Conv2D)                (None, 112, 112, 48) 8256        max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 112, 112, 48) 192         conv1_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)       (None, 112, 112, 48) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv1_1 (Conv2D)                (None, 112, 112, 48) 20784       leaky_re_lu_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat1 (Concatenate)           (None, 112, 112, 67) 0           conv1_1[0][0]                    \n",
      "                                                                 max_pooling2d[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 112, 112, 67) 268         concat1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)       (None, 112, 112, 67) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 56, 56, 67)   0           leaky_re_lu_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2_0 (Conv2D)                (None, 56, 56, 144)  86976       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 56, 56, 144)  576         conv2_0[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)       (None, 56, 56, 144)  0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2_1 (Conv2D)                (None, 56, 56, 144)  186768      leaky_re_lu_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concat2 (Concatenate)           (None, 56, 56, 211)  0           conv2_1[0][0]                    \n",
      "                                                                 max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 56, 56, 211)  844         concat2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)       (None, 56, 56, 211)  0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 28, 28, 211)  0           leaky_re_lu_5[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 165424)       0           max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 165424)       0           flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 128)          21174400    dropout[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)       (None, 128)          0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2)            258         leaky_re_lu_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "output (Activation)             (None, 2)            0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 21,482,230\n",
      "Trainable params: 21,481,220\n",
      "Non-trainable params: 1,010\n",
      "__________________________________________________________________________________________________\n",
      "histogram type <class 'numpy.ndarray'> [1461   28]\n",
      "***** class weight [26.589285714285715, 0.07643737166324435]\n",
      "Epoch 1/3\n",
      " 1/47 [..............................] - ETA: 0s - loss: 702.4736 - accuracy: 0.0000e+00 - precision: 0.0000e+00 - recall: 0.0000e+00 - auc: 0.0000e+00 - f1score: 0.0000e+00WARNING:tensorflow:From /home/ubuntu/anaconda3/envs/tensorflow2_latest_p37/gpu/lib/python3.7/site-packages/tensorflow/python/ops/summary_ops_v2.py:1277: stop (from tensorflow.python.eager.profiler) is deprecated and will be removed after 2020-07-01.\n",
      "Instructions for updating:\n",
      "use `tf.profiler.experimental.stop` instead.\n",
      "47/47 [==============================] - 79s 2s/step - loss: 687.5279 - accuracy: 0.2035 - precision: 0.0183 - recall: 0.7857 - auc: 0.1388 - f1score: 0.0358 - val_loss: 658.1638 - val_accuracy: 0.0822 - val_precision: 0.0219 - val_recall: 1.0000 - val_auc: 0.0460 - val_f1score: 0.0429\n",
      "Epoch 2/3\n",
      "47/47 [==============================] - 75s 2s/step - loss: 653.8196 - accuracy: 0.3022 - precision: 0.0236 - recall: 0.8929 - auc: 0.2548 - f1score: 0.0459 - val_loss: 549.0499 - val_accuracy: 0.0342 - val_precision: 0.0208 - val_recall: 1.0000 - val_auc: 0.0281 - val_f1score: 0.0408\n",
      "Epoch 3/3\n",
      "47/47 [==============================] - 74s 2s/step - loss: 626.6279 - accuracy: 0.3432 - precision: 0.0250 - recall: 0.8929 - auc: 0.2888 - f1score: 0.0486 - val_loss: 515.6927 - val_accuracy: 0.1233 - val_precision: 0.0229 - val_recall: 1.0000 - val_auc: 0.0832 - val_f1score: 0.0448\n",
      "6/6 [==============================] - 5s 899ms/step - loss: 518.2538 - accuracy: 0.1319 - precision: 0.0188 - recall: 0.7500 - auc: 0.0754 - f1score: 0.0366 \n",
      "loss  =  518.2538452148438\n",
      "accuracy  =  0.1318681389093399\n",
      "precision  =  0.01875000074505806\n",
      "recall  =  0.75\n",
      "auc  =  0.07536831498146057\n",
      "f1score  =  0.03658536821603775\n",
      "True (-)ves:  21 \n",
      "False (+)ves:  157 \n",
      "False (-)ves:  1 \n",
      "True (+)ves:  3\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    cfg = yaml.full_load(open(\"/home/ubuntu/covid-cxr/config.yml\", 'r'))\n",
    "    cfg['TRAIN']['EXPERIMENT_TYPE']\n",
    "    train_experiment(cfg=cfg, experiment=cfg['TRAIN']['EXPERIMENT_TYPE'], save_weights=True, write_logs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hostname: ip-172-31-82-217\n",
      "IP Address: 172.31.82.217\n"
     ]
    }
   ],
   "source": [
    "import socket\n",
    "## getting the hostname by socket.gethostname() method\n",
    "hostname = socket.gethostname()\n",
    "## getting the IP address using socket.gethostbyname() method\n",
    "ip_address = socket.gethostbyname(hostname)\n",
    "## printing the hostname and ip_address\n",
    "print(f\"Hostname: {hostname}\")\n",
    "print(f\"IP Address: {ip_address}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find `tensorboard`. Please ensure that your PATH\n",
       "contains an executable `tensorboard` program, or explicitly specify\n",
       "the path to a TensorBoard binary by setting the `TENSORBOARD_BINARY`\n",
       "environment variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir /home/ubuntu/covid-cxr/results/logs --host {ip_address}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
